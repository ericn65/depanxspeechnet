{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning From English to Spanish\n",
    "In this notebook we are going to check how is the pre-trained network working over spanish data on english pretrained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ericq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from data_Loader import dataLoaderPickle, justDatasetLoaderPickle, dataCreator, dataSaver, dataMLTCreator\n",
    "from networks_v2 import AttentionModel, AnxietyFromDepression, HydraNetTL, Scripted2Unscripted\n",
    "from optimizer import train2, test2, optimizerNet, test, train, testMLT, trainMLT\n",
    "from optimizer import IterMeter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split, SubsetRandomSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = \"C:\\\\Users\\\\ericq\\\\OneDrive\\\\Escriptori\\\\TELECOM\\\\MSC MATT\\\\TFM\\\\The research question\\\\The Solution\\\\CNN+RNN\\\\Raw_Data_v2\\\\RADAR-MDD-CIBER-s1\\\\RADAR-MDD-CIBER-s1\"\n",
    "test_loader = \"\"\n",
    "\n",
    "name =[]\n",
    "data = []\n",
    "audio = []\n",
    "\n",
    "name = [x[0] for x in os.walk(train_loader)]\n",
    "\n",
    "name.pop(0)\n",
    "dataset_esp, spectrograms, labels_dep, labels_anx = dataMLTCreator(train_loader, pickleName=\"Scripted_Esp_PHQ8_MLT1\", task=\"scripted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = \"C:\\\\Users\\\\ericq\\\\OneDrive\\\\Escriptori\\\\TELECOM\\\\MSC MATT\\\\TFM\\\\The research question\\\\The Solution\\\\CNN+RNN\\\\Raw_Data_v2\\\\RADAR-MDD-IISPV-s1\\\\RADAR-MDD-IISPV-s1\" \n",
    "\n",
    "dataset_esp2, spectrograms2, labels_dep2, labels_anx2 = dataMLTCreator(train_loader, pickleName=\"Scripted_Esp_PHQ8_MLT2\", task=\"scripted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "spectrograms = np.concatenate((spectrograms, spectrograms2))\n",
    "labels_dep = np.concatenate((labels_dep, labels_dep2))\n",
    "labels_anx = np.concatenate((labels_anx, labels_anx2))\n",
    "\n",
    "dataset_esp_tot = TensorDataset(\n",
    "        torch.from_numpy(spectrograms),\n",
    "        torch.from_numpy(labels_dep),\n",
    "        torch.from_numpy(labels_anx)\n",
    "    )\n",
    "\n",
    "dataSaver(dataset_esp_tot, \"Scripted_Esp_MLT_Tot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_esp_tot = justDatasetLoaderPickle(\"Scripted_Esp_MLT_Tot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = []\n",
    "import matplotlib.pyplot as plt\n",
    "for x, y,z in dataset_esp_tot:\n",
    "    tar.append(y)\n",
    "\n",
    "n, bins, patches = plt.hist(x=tar,bins='auto',color='#0504aa',alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y',alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Is my data balanced?')\n",
    "plt.text(23,45,r'$\\mu15, b=3$')\n",
    "maxfreq = n.max()\n",
    "plt.ylim(ymax=np.ceil(maxfreq/10)*10 if maxfreq % 10 else maxfreq + 10)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "learning_Rate = 0.0005\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "experiment = Experiment(api_key='dummy_key', disabled=True)\n",
    "\n",
    "hparams = {\n",
    "    \"n_cnn_layers\": 6,\n",
    "    \"n_rnn_layers\": 1,\n",
    "    \"rnn_dim\": 256,\n",
    "    \"h_rnn_layers\": 128,\n",
    "    \"n_class\": 5,\n",
    "    \"n_feats\": 64,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": learning_Rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs\n",
    "}\n",
    "\n",
    "experiment.log_parameters(hparams)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(7)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:\\\\Users\\\\ericq\\\\OneDrive\\\\Escriptori\\\\TELECOM\\\\MSC MATT\\\\TFM\\\\The research question\\\\The Solution\\\\CNN+RNN\\\\model_PHQ8_Scripted_Eng.pt\"\n",
    "infile = open(filename, 'rb')\n",
    "model_pretrained = torch.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}\n",
    "\n",
    "#Optimizing Model\n",
    "weights = [1.0, 0.95, 0.9, 0.75, 0.95]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "criterion_dep = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "criterion_anx = nn.CrossEntropyLoss().to(device)\n",
    "iter_meter = IterMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn \n",
    "import pandas as pd\n",
    "import torch.nn.functional as F \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainXD(epochs, model_mlt, train_loader, optimizer, criterion, iter_meter):\n",
    "    acc_dep_list = []\n",
    "    loss_list = []\n",
    "    label_dep_list = []\n",
    "    predicted_list_dep = []\n",
    "    loss_tot_list = []\n",
    "    accuracy_dep = []\n",
    "\n",
    "    #Training\n",
    "    for epoch in range(epochs):\n",
    "        model_mlt.train()\n",
    "        total_training_loss = 0\n",
    "\n",
    "        for x,y,z in train_loader:\n",
    "            inputs = x\n",
    "            label_dep = y.long()\n",
    "            label_dep_list.extend(label_dep.detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            phq8 = model_mlt(inputs.float())\n",
    "            phq8 = phq8.squeeze(0)\n",
    "\n",
    "            predicted_list_dep.extend((torch.max(torch.exp(F.log_softmax(phq8,dim=1)),1)[1]).detach().numpy())\n",
    "\n",
    "            loss = criterion_dep(phq8,label_dep)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_meter.step()\n",
    "            total_training_loss += loss\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            #Track accuracy\n",
    "            total_dep = label_dep.size(0)\n",
    "            _, predicted = torch.max(phq8.data,1)\n",
    "            correct_dep = (predicted == label_dep).sum().item()\n",
    "            acc_dep_list.append(correct_dep/total_dep)  \n",
    "\n",
    "        print('Train Epoch: {} \\tLoss: {:.4f}\\tDepression Accuracy: {:.4f}'.format(\n",
    "            epoch,\n",
    "            np.mean(loss_list),\n",
    "            np.mean(acc_dep_list)\n",
    "        ))      \n",
    "        loss_tot_list.append(np.mean(loss_list))\n",
    "        accuracy_dep.append(np.mean(acc_dep_list))\n",
    "        \n",
    "    #Printing Confusion Matrix\n",
    "    classes_dep = ('0','1','2','3','4')\n",
    "    cf_matrix_dep = confusion_matrix(label_dep_list, predicted_list_dep)\n",
    "    df_cm = pd.DataFrame(cf_matrix_dep/np.sum(cf_matrix_dep)*10,index = [i for i in classes_dep], columns=[i for i in classes_dep])\n",
    "    plt.figure(figsize=(12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('Confusion Matrix Depression Training')\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].plot(range(epochs), loss_tot_list)\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].set(xlabel= 'Epoch', ylabel='Loss')\n",
    "    axs[1].plot(range(epochs), accuracy_dep)\n",
    "    axs[1].set_title('Training Depression Accuracy')\n",
    "    axs[1].set(xlabel= 'Epoch', ylabel='Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testXD(epochs, model_mlt, train_loader, optimizer, criterion, iter_meter):\n",
    "    acc_dep_list = []\n",
    "    loss_list = []\n",
    "    label_dep_list = []\n",
    "    predicted_list_dep = []\n",
    "    loss_tot_list = []\n",
    "    accuracy_dep = []\n",
    "\n",
    "    #Training\n",
    "    for epoch in range(epochs):\n",
    "        model_mlt.train()\n",
    "        total_training_loss = 0\n",
    "\n",
    "        for x,y,z in train_loader:\n",
    "            inputs = x\n",
    "            label_dep = y.long()\n",
    "            label_dep_list.extend(label_dep.detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            phq8 = model_mlt(inputs.float())\n",
    "            phq8 = phq8.squeeze(0)\n",
    "\n",
    "            predicted_list_dep.extend((torch.max(torch.exp(F.log_softmax(phq8,dim=1)),1)[1]).detach().numpy())\n",
    "\n",
    "            loss = criterion_dep(phq8,label_dep)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_meter.step()\n",
    "            total_training_loss += loss\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            #Track accuracy\n",
    "            total_dep = label_dep.size(0)\n",
    "            _, predicted = torch.max(phq8.data,1)\n",
    "            correct_dep = (predicted == label_dep).sum().item()\n",
    "            acc_dep_list.append(correct_dep/total_dep)  \n",
    "\n",
    "        print('Test Epoch: {} \\tLoss: {:.4f}\\tDepression Accuracy: {:.4f}'.format(\n",
    "            epoch,\n",
    "            np.mean(loss_list),\n",
    "            np.mean(acc_dep_list)\n",
    "        ))      \n",
    "        loss_tot_list.append(np.mean(loss_list))\n",
    "        accuracy_dep.append(np.mean(acc_dep_list))\n",
    "        \n",
    "    #Printing Confusion Matrix\n",
    "    classes_dep = ('0','1','2','3','4')\n",
    "    cf_matrix_dep = confusion_matrix(label_dep_list, predicted_list_dep)\n",
    "    df_cm = pd.DataFrame(cf_matrix_dep/np.sum(cf_matrix_dep)*10,index = [i for i in classes_dep], columns=[i for i in classes_dep])\n",
    "    plt.figure(figsize=(12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('Confusion Matrix Depression Testing')\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "    axs[0].plot(range(epochs), loss_tot_list)\n",
    "    axs[0].set_title('Test Loss')\n",
    "    axs[0].set(xlabel= 'Epoch', ylabel='Loss')\n",
    "    axs[1].plot(range(epochs), accuracy_dep)\n",
    "    axs[1].set_title('Test Depression Accuracy')\n",
    "    axs[1].set(xlabel= 'Epoch', ylabel='Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Epoch: 0 \tLoss: 1.7341\tDepression Accuracy: 0.2599\n",
      "Train Epoch: 1 \tLoss: 1.6473\tDepression Accuracy: 0.2753\n",
      "Train Epoch: 2 \tLoss: 1.6010\tDepression Accuracy: 0.2836\n",
      "Train Epoch: 3 \tLoss: 1.5710\tDepression Accuracy: 0.2927\n",
      "Train Epoch: 4 \tLoss: 1.5483\tDepression Accuracy: 0.3019\n",
      "Train Epoch: 5 \tLoss: 1.5302\tDepression Accuracy: 0.3093\n",
      "Train Epoch: 6 \tLoss: 1.5161\tDepression Accuracy: 0.3160\n",
      "Train Epoch: 7 \tLoss: 1.5058\tDepression Accuracy: 0.3202\n",
      "Train Epoch: 8 \tLoss: 1.4957\tDepression Accuracy: 0.3249\n",
      "Train Epoch: 9 \tLoss: 1.4868\tDepression Accuracy: 0.3297\n",
      "Train Epoch: 10 \tLoss: 1.4783\tDepression Accuracy: 0.3339\n",
      "Train Epoch: 11 \tLoss: 1.4709\tDepression Accuracy: 0.3382\n",
      "Train Epoch: 12 \tLoss: 1.4637\tDepression Accuracy: 0.3422\n",
      "Train Epoch: 13 \tLoss: 1.4572\tDepression Accuracy: 0.3460\n",
      "Train Epoch: 14 \tLoss: 1.4513\tDepression Accuracy: 0.3495\n",
      "Train Epoch: 15 \tLoss: 1.4458\tDepression Accuracy: 0.3530\n",
      "Train Epoch: 16 \tLoss: 1.4406\tDepression Accuracy: 0.3565\n",
      "Train Epoch: 17 \tLoss: 1.4354\tDepression Accuracy: 0.3597\n",
      "Train Epoch: 18 \tLoss: 1.4305\tDepression Accuracy: 0.3630\n",
      "Train Epoch: 19 \tLoss: 1.4257\tDepression Accuracy: 0.3657\n",
      "Train Epoch: 20 \tLoss: 1.4213\tDepression Accuracy: 0.3685\n",
      "Train Epoch: 21 \tLoss: 1.4169\tDepression Accuracy: 0.3714\n",
      "Train Epoch: 22 \tLoss: 1.4125\tDepression Accuracy: 0.3744\n",
      "Train Epoch: 23 \tLoss: 1.4084\tDepression Accuracy: 0.3771\n",
      "Train Epoch: 24 \tLoss: 1.4043\tDepression Accuracy: 0.3798\n",
      "Train Epoch: 25 \tLoss: 1.4002\tDepression Accuracy: 0.3826\n",
      "Train Epoch: 26 \tLoss: 1.3963\tDepression Accuracy: 0.3854\n",
      "Train Epoch: 27 \tLoss: 1.3924\tDepression Accuracy: 0.3880\n",
      "Train Epoch: 28 \tLoss: 1.3887\tDepression Accuracy: 0.3908\n",
      "Train Epoch: 29 \tLoss: 1.3851\tDepression Accuracy: 0.3932\n",
      "Train Epoch: 30 \tLoss: 1.3815\tDepression Accuracy: 0.3956\n",
      "Train Epoch: 31 \tLoss: 1.3781\tDepression Accuracy: 0.3980\n",
      "Train Epoch: 32 \tLoss: 1.3747\tDepression Accuracy: 0.4004\n",
      "Train Epoch: 33 \tLoss: 1.3714\tDepression Accuracy: 0.4027\n",
      "Train Epoch: 34 \tLoss: 1.3680\tDepression Accuracy: 0.4051\n",
      "Train Epoch: 35 \tLoss: 1.3649\tDepression Accuracy: 0.4072\n",
      "Train Epoch: 36 \tLoss: 1.3618\tDepression Accuracy: 0.4094\n",
      "Train Epoch: 37 \tLoss: 1.3589\tDepression Accuracy: 0.4116\n",
      "Train Epoch: 38 \tLoss: 1.3558\tDepression Accuracy: 0.4139\n",
      "Train Epoch: 39 \tLoss: 1.3529\tDepression Accuracy: 0.4158\n",
      "Train Epoch: 40 \tLoss: 1.3498\tDepression Accuracy: 0.4180\n",
      "Train Epoch: 41 \tLoss: 1.3469\tDepression Accuracy: 0.4201\n",
      "Train Epoch: 42 \tLoss: 1.3440\tDepression Accuracy: 0.4222\n",
      "Train Epoch: 43 \tLoss: 1.3410\tDepression Accuracy: 0.4243\n",
      "Train Epoch: 44 \tLoss: 1.3382\tDepression Accuracy: 0.4263\n",
      "Train Epoch: 45 \tLoss: 1.3355\tDepression Accuracy: 0.4280\n",
      "Train Epoch: 46 \tLoss: 1.3328\tDepression Accuracy: 0.4300\n",
      "Train Epoch: 47 \tLoss: 1.3299\tDepression Accuracy: 0.4320\n",
      "Train Epoch: 48 \tLoss: 1.3271\tDepression Accuracy: 0.4338\n",
      "Train Epoch: 49 \tLoss: 1.3243\tDepression Accuracy: 0.4358\n",
      "Train Epoch: 50 \tLoss: 1.3216\tDepression Accuracy: 0.4378\n",
      "Train Epoch: 51 \tLoss: 1.3189\tDepression Accuracy: 0.4396\n",
      "Train Epoch: 52 \tLoss: 1.3162\tDepression Accuracy: 0.4417\n",
      "Train Epoch: 53 \tLoss: 1.3135\tDepression Accuracy: 0.4437\n",
      "Train Epoch: 54 \tLoss: 1.3108\tDepression Accuracy: 0.4453\n",
      "Train Epoch: 55 \tLoss: 1.3082\tDepression Accuracy: 0.4472\n",
      "Train Epoch: 56 \tLoss: 1.3056\tDepression Accuracy: 0.4489\n",
      "Train Epoch: 57 \tLoss: 1.3030\tDepression Accuracy: 0.4508\n",
      "Train Epoch: 58 \tLoss: 1.3005\tDepression Accuracy: 0.4526\n",
      "Train Epoch: 59 \tLoss: 1.2981\tDepression Accuracy: 0.4543\n",
      "Train Epoch: 60 \tLoss: 1.2956\tDepression Accuracy: 0.4562\n",
      "Train Epoch: 61 \tLoss: 1.2930\tDepression Accuracy: 0.4580\n",
      "Train Epoch: 62 \tLoss: 1.2906\tDepression Accuracy: 0.4597\n",
      "Train Epoch: 63 \tLoss: 1.2881\tDepression Accuracy: 0.4614\n",
      "Train Epoch: 64 \tLoss: 1.2857\tDepression Accuracy: 0.4631\n",
      "Train Epoch: 65 \tLoss: 1.2833\tDepression Accuracy: 0.4648\n",
      "Train Epoch: 66 \tLoss: 1.2809\tDepression Accuracy: 0.4665\n",
      "Train Epoch: 67 \tLoss: 1.2785\tDepression Accuracy: 0.4682\n",
      "Train Epoch: 68 \tLoss: 1.2761\tDepression Accuracy: 0.4699\n",
      "Train Epoch: 69 \tLoss: 1.2737\tDepression Accuracy: 0.4716\n",
      "Train Epoch: 70 \tLoss: 1.2713\tDepression Accuracy: 0.4732\n",
      "Train Epoch: 71 \tLoss: 1.2690\tDepression Accuracy: 0.4750\n",
      "Train Epoch: 72 \tLoss: 1.2667\tDepression Accuracy: 0.4767\n",
      "Train Epoch: 73 \tLoss: 1.2644\tDepression Accuracy: 0.4782\n",
      "Train Epoch: 74 \tLoss: 1.2622\tDepression Accuracy: 0.4798\n",
      "Train Epoch: 75 \tLoss: 1.2599\tDepression Accuracy: 0.4813\n",
      "Train Epoch: 76 \tLoss: 1.2576\tDepression Accuracy: 0.4829\n",
      "Train Epoch: 77 \tLoss: 1.2553\tDepression Accuracy: 0.4844\n",
      "Train Epoch: 78 \tLoss: 1.2531\tDepression Accuracy: 0.4859\n",
      "Train Epoch: 79 \tLoss: 1.2509\tDepression Accuracy: 0.4876\n",
      "Train Epoch: 80 \tLoss: 1.2487\tDepression Accuracy: 0.4891\n",
      "Train Epoch: 81 \tLoss: 1.2464\tDepression Accuracy: 0.4906\n",
      "Train Epoch: 82 \tLoss: 1.2442\tDepression Accuracy: 0.4922\n",
      "Train Epoch: 83 \tLoss: 1.2419\tDepression Accuracy: 0.4937\n",
      "Train Epoch: 84 \tLoss: 1.2397\tDepression Accuracy: 0.4953\n",
      "Train Epoch: 85 \tLoss: 1.2376\tDepression Accuracy: 0.4969\n",
      "Train Epoch: 86 \tLoss: 1.2354\tDepression Accuracy: 0.4984\n",
      "Train Epoch: 87 \tLoss: 1.2332\tDepression Accuracy: 0.4999\n",
      "Train Epoch: 88 \tLoss: 1.2310\tDepression Accuracy: 0.5016\n",
      "Train Epoch: 89 \tLoss: 1.2289\tDepression Accuracy: 0.5030\n",
      "Train Epoch: 90 \tLoss: 1.2268\tDepression Accuracy: 0.5046\n",
      "Train Epoch: 91 \tLoss: 1.2247\tDepression Accuracy: 0.5060\n",
      "Train Epoch: 92 \tLoss: 1.2225\tDepression Accuracy: 0.5075\n",
      "Train Epoch: 93 \tLoss: 1.2204\tDepression Accuracy: 0.5090\n",
      "Train Epoch: 94 \tLoss: 1.2184\tDepression Accuracy: 0.5104\n",
      "Train Epoch: 95 \tLoss: 1.2163\tDepression Accuracy: 0.5119\n",
      "Train Epoch: 96 \tLoss: 1.2143\tDepression Accuracy: 0.5133\n",
      "Train Epoch: 97 \tLoss: 1.2122\tDepression Accuracy: 0.5147\n",
      "Train Epoch: 98 \tLoss: 1.2102\tDepression Accuracy: 0.5161\n",
      "Train Epoch: 99 \tLoss: 1.2082\tDepression Accuracy: 0.5175\n",
      "Train Epoch: 100 \tLoss: 1.2061\tDepression Accuracy: 0.5189\n",
      "Train Epoch: 101 \tLoss: 1.2041\tDepression Accuracy: 0.5203\n",
      "Train Epoch: 102 \tLoss: 1.2021\tDepression Accuracy: 0.5218\n",
      "Train Epoch: 103 \tLoss: 1.2000\tDepression Accuracy: 0.5233\n",
      "Train Epoch: 104 \tLoss: 1.1980\tDepression Accuracy: 0.5246\n",
      "Train Epoch: 105 \tLoss: 1.1960\tDepression Accuracy: 0.5260\n",
      "Train Epoch: 106 \tLoss: 1.1940\tDepression Accuracy: 0.5274\n",
      "Train Epoch: 107 \tLoss: 1.1920\tDepression Accuracy: 0.5287\n",
      "Train Epoch: 108 \tLoss: 1.1900\tDepression Accuracy: 0.5301\n",
      "Train Epoch: 109 \tLoss: 1.1880\tDepression Accuracy: 0.5315\n",
      "Train Epoch: 110 \tLoss: 1.1860\tDepression Accuracy: 0.5328\n",
      "Train Epoch: 111 \tLoss: 1.1841\tDepression Accuracy: 0.5342\n",
      "Train Epoch: 112 \tLoss: 1.1821\tDepression Accuracy: 0.5355\n",
      "Train Epoch: 113 \tLoss: 1.1801\tDepression Accuracy: 0.5368\n",
      "Train Epoch: 114 \tLoss: 1.1782\tDepression Accuracy: 0.5381\n",
      "Train Epoch: 115 \tLoss: 1.1762\tDepression Accuracy: 0.5395\n",
      "Train Epoch: 116 \tLoss: 1.1742\tDepression Accuracy: 0.5409\n",
      "Train Epoch: 117 \tLoss: 1.1723\tDepression Accuracy: 0.5422\n",
      "Train Epoch: 118 \tLoss: 1.1703\tDepression Accuracy: 0.5435\n",
      "Train Epoch: 119 \tLoss: 1.1684\tDepression Accuracy: 0.5448\n",
      "Train Epoch: 120 \tLoss: 1.1665\tDepression Accuracy: 0.5461\n",
      "Train Epoch: 121 \tLoss: 1.1645\tDepression Accuracy: 0.5474\n",
      "Train Epoch: 122 \tLoss: 1.1626\tDepression Accuracy: 0.5486\n",
      "Train Epoch: 123 \tLoss: 1.1607\tDepression Accuracy: 0.5499\n",
      "Train Epoch: 124 \tLoss: 1.1589\tDepression Accuracy: 0.5511\n",
      "Train Epoch: 125 \tLoss: 1.1570\tDepression Accuracy: 0.5524\n",
      "Train Epoch: 126 \tLoss: 1.1551\tDepression Accuracy: 0.5537\n",
      "Train Epoch: 127 \tLoss: 1.1532\tDepression Accuracy: 0.5549\n",
      "Train Epoch: 128 \tLoss: 1.1514\tDepression Accuracy: 0.5562\n",
      "Train Epoch: 129 \tLoss: 1.1495\tDepression Accuracy: 0.5574\n",
      "Train Epoch: 130 \tLoss: 1.1476\tDepression Accuracy: 0.5587\n",
      "Train Epoch: 131 \tLoss: 1.1458\tDepression Accuracy: 0.5599\n",
      "Train Epoch: 132 \tLoss: 1.1439\tDepression Accuracy: 0.5611\n",
      "Train Epoch: 133 \tLoss: 1.1420\tDepression Accuracy: 0.5624\n",
      "Train Epoch: 134 \tLoss: 1.1402\tDepression Accuracy: 0.5636\n",
      "Train Epoch: 135 \tLoss: 1.1383\tDepression Accuracy: 0.5649\n",
      "Train Epoch: 136 \tLoss: 1.1365\tDepression Accuracy: 0.5660\n",
      "Train Epoch: 137 \tLoss: 1.1347\tDepression Accuracy: 0.5672\n",
      "Train Epoch: 138 \tLoss: 1.1329\tDepression Accuracy: 0.5684\n",
      "Train Epoch: 139 \tLoss: 1.1311\tDepression Accuracy: 0.5696\n",
      "Train Epoch: 140 \tLoss: 1.1293\tDepression Accuracy: 0.5708\n",
      "Train Epoch: 141 \tLoss: 1.1275\tDepression Accuracy: 0.5719\n",
      "Train Epoch: 142 \tLoss: 1.1257\tDepression Accuracy: 0.5731\n",
      "Train Epoch: 143 \tLoss: 1.1239\tDepression Accuracy: 0.5743\n",
      "Train Epoch: 144 \tLoss: 1.1221\tDepression Accuracy: 0.5755\n",
      "Train Epoch: 145 \tLoss: 1.1204\tDepression Accuracy: 0.5766\n",
      "Train Epoch: 146 \tLoss: 1.1186\tDepression Accuracy: 0.5777\n",
      "Train Epoch: 147 \tLoss: 1.1168\tDepression Accuracy: 0.5790\n",
      "Train Epoch: 148 \tLoss: 1.1150\tDepression Accuracy: 0.5801\n",
      "Train Epoch: 149 \tLoss: 1.1132\tDepression Accuracy: 0.5812\n",
      "Train Epoch: 150 \tLoss: 1.1115\tDepression Accuracy: 0.5823\n",
      "Train Epoch: 151 \tLoss: 1.1097\tDepression Accuracy: 0.5835\n",
      "Train Epoch: 152 \tLoss: 1.1079\tDepression Accuracy: 0.5846\n",
      "Train Epoch: 153 \tLoss: 1.1062\tDepression Accuracy: 0.5856\n",
      "Train Epoch: 154 \tLoss: 1.1044\tDepression Accuracy: 0.5867\n",
      "Train Epoch: 155 \tLoss: 1.1027\tDepression Accuracy: 0.5878\n",
      "Train Epoch: 156 \tLoss: 1.1010\tDepression Accuracy: 0.5889\n",
      "Train Epoch: 157 \tLoss: 1.0993\tDepression Accuracy: 0.5900\n",
      "Train Epoch: 158 \tLoss: 1.0975\tDepression Accuracy: 0.5911\n",
      "Train Epoch: 159 \tLoss: 1.0958\tDepression Accuracy: 0.5922\n",
      "Train Epoch: 160 \tLoss: 1.0940\tDepression Accuracy: 0.5933\n",
      "Train Epoch: 161 \tLoss: 1.0923\tDepression Accuracy: 0.5944\n",
      "Train Epoch: 162 \tLoss: 1.0906\tDepression Accuracy: 0.5955\n",
      "Train Epoch: 163 \tLoss: 1.0888\tDepression Accuracy: 0.5966\n",
      "Train Epoch: 164 \tLoss: 1.0871\tDepression Accuracy: 0.5976\n",
      "Train Epoch: 165 \tLoss: 1.0854\tDepression Accuracy: 0.5987\n",
      "Train Epoch: 166 \tLoss: 1.0836\tDepression Accuracy: 0.5998\n",
      "Train Epoch: 167 \tLoss: 1.0819\tDepression Accuracy: 0.6008\n",
      "Train Epoch: 168 \tLoss: 1.0802\tDepression Accuracy: 0.6019\n",
      "Train Epoch: 169 \tLoss: 1.0785\tDepression Accuracy: 0.6030\n",
      "Train Epoch: 170 \tLoss: 1.0768\tDepression Accuracy: 0.6040\n",
      "Train Epoch: 171 \tLoss: 1.0751\tDepression Accuracy: 0.6051\n",
      "Train Epoch: 172 \tLoss: 1.0734\tDepression Accuracy: 0.6061\n",
      "Train Epoch: 173 \tLoss: 1.0718\tDepression Accuracy: 0.6072\n",
      "Train Epoch: 174 \tLoss: 1.0701\tDepression Accuracy: 0.6082\n",
      "Train Epoch: 175 \tLoss: 1.0684\tDepression Accuracy: 0.6092\n",
      "Train Epoch: 176 \tLoss: 1.0668\tDepression Accuracy: 0.6103\n",
      "Train Epoch: 177 \tLoss: 1.0651\tDepression Accuracy: 0.6113\n",
      "Train Epoch: 178 \tLoss: 1.0634\tDepression Accuracy: 0.6123\n",
      "Train Epoch: 179 \tLoss: 1.0617\tDepression Accuracy: 0.6134\n",
      "Train Epoch: 180 \tLoss: 1.0601\tDepression Accuracy: 0.6144\n",
      "Train Epoch: 181 \tLoss: 1.0584\tDepression Accuracy: 0.6154\n",
      "Train Epoch: 182 \tLoss: 1.0568\tDepression Accuracy: 0.6164\n",
      "Train Epoch: 183 \tLoss: 1.0551\tDepression Accuracy: 0.6174\n",
      "Train Epoch: 184 \tLoss: 1.0535\tDepression Accuracy: 0.6184\n",
      "Train Epoch: 185 \tLoss: 1.0518\tDepression Accuracy: 0.6194\n",
      "Train Epoch: 186 \tLoss: 1.0502\tDepression Accuracy: 0.6204\n",
      "Train Epoch: 187 \tLoss: 1.0486\tDepression Accuracy: 0.6213\n",
      "Train Epoch: 188 \tLoss: 1.0470\tDepression Accuracy: 0.6223\n",
      "Train Epoch: 189 \tLoss: 1.0454\tDepression Accuracy: 0.6233\n",
      "Train Epoch: 190 \tLoss: 1.0437\tDepression Accuracy: 0.6243\n",
      "Train Epoch: 191 \tLoss: 1.0421\tDepression Accuracy: 0.6252\n",
      "Train Epoch: 192 \tLoss: 1.0405\tDepression Accuracy: 0.6262\n",
      "Train Epoch: 193 \tLoss: 1.0389\tDepression Accuracy: 0.6271\n",
      "Train Epoch: 194 \tLoss: 1.0373\tDepression Accuracy: 0.6281\n",
      "Train Epoch: 195 \tLoss: 1.0357\tDepression Accuracy: 0.6290\n",
      "Train Epoch: 196 \tLoss: 1.0341\tDepression Accuracy: 0.6300\n",
      "Train Epoch: 197 \tLoss: 1.0325\tDepression Accuracy: 0.6309\n",
      "Train Epoch: 198 \tLoss: 1.0309\tDepression Accuracy: 0.6319\n",
      "Train Epoch: 199 \tLoss: 1.0293\tDepression Accuracy: 0.6328\n",
      "Train Epoch: 200 \tLoss: 1.0277\tDepression Accuracy: 0.6338\n",
      "Train Epoch: 201 \tLoss: 1.0261\tDepression Accuracy: 0.6347\n",
      "Train Epoch: 202 \tLoss: 1.0245\tDepression Accuracy: 0.6356\n",
      "Train Epoch: 203 \tLoss: 1.0230\tDepression Accuracy: 0.6366\n",
      "Train Epoch: 204 \tLoss: 1.0214\tDepression Accuracy: 0.6375\n",
      "Train Epoch: 205 \tLoss: 1.0198\tDepression Accuracy: 0.6384\n",
      "Train Epoch: 206 \tLoss: 1.0182\tDepression Accuracy: 0.6394\n",
      "Train Epoch: 207 \tLoss: 1.0166\tDepression Accuracy: 0.6403\n",
      "Train Epoch: 208 \tLoss: 1.0150\tDepression Accuracy: 0.6412\n",
      "Train Epoch: 209 \tLoss: 1.0135\tDepression Accuracy: 0.6421\n",
      "Train Epoch: 210 \tLoss: 1.0119\tDepression Accuracy: 0.6430\n",
      "Train Epoch: 211 \tLoss: 1.0104\tDepression Accuracy: 0.6439\n",
      "Train Epoch: 212 \tLoss: 1.0088\tDepression Accuracy: 0.6448\n",
      "Train Epoch: 213 \tLoss: 1.0073\tDepression Accuracy: 0.6457\n",
      "Train Epoch: 214 \tLoss: 1.0057\tDepression Accuracy: 0.6466\n",
      "Train Epoch: 215 \tLoss: 1.0042\tDepression Accuracy: 0.6474\n",
      "Train Epoch: 216 \tLoss: 1.0027\tDepression Accuracy: 0.6483\n",
      "Train Epoch: 217 \tLoss: 1.0011\tDepression Accuracy: 0.6492\n",
      "Train Epoch: 218 \tLoss: 0.9996\tDepression Accuracy: 0.6501\n",
      "Train Epoch: 219 \tLoss: 0.9981\tDepression Accuracy: 0.6509\n",
      "Train Epoch: 220 \tLoss: 0.9965\tDepression Accuracy: 0.6518\n",
      "Train Epoch: 221 \tLoss: 0.9950\tDepression Accuracy: 0.6527\n",
      "Train Epoch: 222 \tLoss: 0.9934\tDepression Accuracy: 0.6536\n",
      "Train Epoch: 223 \tLoss: 0.9919\tDepression Accuracy: 0.6544\n",
      "Train Epoch: 224 \tLoss: 0.9904\tDepression Accuracy: 0.6553\n",
      "Train Epoch: 225 \tLoss: 0.9889\tDepression Accuracy: 0.6561\n",
      "Train Epoch: 226 \tLoss: 0.9873\tDepression Accuracy: 0.6570\n",
      "Train Epoch: 227 \tLoss: 0.9859\tDepression Accuracy: 0.6578\n",
      "Train Epoch: 228 \tLoss: 0.9843\tDepression Accuracy: 0.6587\n",
      "Train Epoch: 229 \tLoss: 0.9828\tDepression Accuracy: 0.6595\n",
      "Train Epoch: 230 \tLoss: 0.9814\tDepression Accuracy: 0.6604\n",
      "Train Epoch: 231 \tLoss: 0.9799\tDepression Accuracy: 0.6612\n",
      "Train Epoch: 232 \tLoss: 0.9784\tDepression Accuracy: 0.6620\n",
      "Train Epoch: 233 \tLoss: 0.9769\tDepression Accuracy: 0.6629\n",
      "Train Epoch: 234 \tLoss: 0.9754\tDepression Accuracy: 0.6637\n",
      "Train Epoch: 235 \tLoss: 0.9739\tDepression Accuracy: 0.6645\n",
      "Train Epoch: 236 \tLoss: 0.9724\tDepression Accuracy: 0.6654\n",
      "Train Epoch: 237 \tLoss: 0.9709\tDepression Accuracy: 0.6661\n",
      "Train Epoch: 238 \tLoss: 0.9694\tDepression Accuracy: 0.6670\n",
      "Train Epoch: 239 \tLoss: 0.9679\tDepression Accuracy: 0.6678\n",
      "Train Epoch: 240 \tLoss: 0.9665\tDepression Accuracy: 0.6686\n",
      "Train Epoch: 241 \tLoss: 0.9650\tDepression Accuracy: 0.6694\n",
      "Train Epoch: 242 \tLoss: 0.9635\tDepression Accuracy: 0.6703\n",
      "Train Epoch: 243 \tLoss: 0.9620\tDepression Accuracy: 0.6711\n",
      "Train Epoch: 244 \tLoss: 0.9605\tDepression Accuracy: 0.6719\n",
      "Train Epoch: 245 \tLoss: 0.9591\tDepression Accuracy: 0.6727\n",
      "Train Epoch: 246 \tLoss: 0.9576\tDepression Accuracy: 0.6735\n",
      "Train Epoch: 247 \tLoss: 0.9561\tDepression Accuracy: 0.6743\n",
      "Train Epoch: 248 \tLoss: 0.9547\tDepression Accuracy: 0.6751\n",
      "Train Epoch: 249 \tLoss: 0.9532\tDepression Accuracy: 0.6759\n",
      "Train Epoch: 250 \tLoss: 0.9517\tDepression Accuracy: 0.6767\n",
      "Train Epoch: 251 \tLoss: 0.9503\tDepression Accuracy: 0.6775\n",
      "Train Epoch: 252 \tLoss: 0.9488\tDepression Accuracy: 0.6783\n",
      "Train Epoch: 253 \tLoss: 0.9474\tDepression Accuracy: 0.6791\n",
      "Train Epoch: 254 \tLoss: 0.9460\tDepression Accuracy: 0.6798\n",
      "Train Epoch: 255 \tLoss: 0.9445\tDepression Accuracy: 0.6806\n",
      "Train Epoch: 256 \tLoss: 0.9431\tDepression Accuracy: 0.6814\n",
      "Train Epoch: 257 \tLoss: 0.9416\tDepression Accuracy: 0.6822\n",
      "Train Epoch: 258 \tLoss: 0.9402\tDepression Accuracy: 0.6829\n",
      "Train Epoch: 259 \tLoss: 0.9388\tDepression Accuracy: 0.6837\n",
      "Train Epoch: 260 \tLoss: 0.9374\tDepression Accuracy: 0.6845\n",
      "Train Epoch: 261 \tLoss: 0.9359\tDepression Accuracy: 0.6852\n",
      "Train Epoch: 262 \tLoss: 0.9345\tDepression Accuracy: 0.6860\n",
      "Train Epoch: 263 \tLoss: 0.9331\tDepression Accuracy: 0.6868\n",
      "Train Epoch: 264 \tLoss: 0.9317\tDepression Accuracy: 0.6875\n",
      "Train Epoch: 265 \tLoss: 0.9302\tDepression Accuracy: 0.6883\n",
      "Train Epoch: 266 \tLoss: 0.9288\tDepression Accuracy: 0.6890\n",
      "Train Epoch: 267 \tLoss: 0.9274\tDepression Accuracy: 0.6898\n",
      "Train Epoch: 268 \tLoss: 0.9260\tDepression Accuracy: 0.6906\n",
      "Train Epoch: 269 \tLoss: 0.9245\tDepression Accuracy: 0.6913\n",
      "Train Epoch: 270 \tLoss: 0.9231\tDepression Accuracy: 0.6920\n",
      "Train Epoch: 271 \tLoss: 0.9217\tDepression Accuracy: 0.6928\n",
      "Train Epoch: 272 \tLoss: 0.9203\tDepression Accuracy: 0.6935\n",
      "Train Epoch: 273 \tLoss: 0.9189\tDepression Accuracy: 0.6942\n",
      "Train Epoch: 274 \tLoss: 0.9175\tDepression Accuracy: 0.6950\n",
      "Train Epoch: 275 \tLoss: 0.9162\tDepression Accuracy: 0.6957\n",
      "Train Epoch: 276 \tLoss: 0.9148\tDepression Accuracy: 0.6964\n",
      "Train Epoch: 277 \tLoss: 0.9134\tDepression Accuracy: 0.6971\n",
      "Train Epoch: 278 \tLoss: 0.9120\tDepression Accuracy: 0.6979\n",
      "Train Epoch: 279 \tLoss: 0.9106\tDepression Accuracy: 0.6986\n",
      "Train Epoch: 280 \tLoss: 0.9092\tDepression Accuracy: 0.6993\n",
      "Train Epoch: 281 \tLoss: 0.9078\tDepression Accuracy: 0.7000\n",
      "Train Epoch: 282 \tLoss: 0.9065\tDepression Accuracy: 0.7007\n",
      "Train Epoch: 283 \tLoss: 0.9051\tDepression Accuracy: 0.7014\n",
      "Train Epoch: 284 \tLoss: 0.9037\tDepression Accuracy: 0.7022\n",
      "Train Epoch: 285 \tLoss: 0.9024\tDepression Accuracy: 0.7029\n",
      "Train Epoch: 286 \tLoss: 0.9010\tDepression Accuracy: 0.7036\n",
      "Train Epoch: 287 \tLoss: 0.8996\tDepression Accuracy: 0.7043\n",
      "Train Epoch: 288 \tLoss: 0.8983\tDepression Accuracy: 0.7050\n",
      "Train Epoch: 289 \tLoss: 0.8969\tDepression Accuracy: 0.7057\n",
      "Train Epoch: 290 \tLoss: 0.8956\tDepression Accuracy: 0.7064\n",
      "Train Epoch: 291 \tLoss: 0.8942\tDepression Accuracy: 0.7071\n",
      "Train Epoch: 292 \tLoss: 0.8929\tDepression Accuracy: 0.7077\n",
      "Train Epoch: 293 \tLoss: 0.8915\tDepression Accuracy: 0.7084\n",
      "Train Epoch: 294 \tLoss: 0.8902\tDepression Accuracy: 0.7091\n",
      "Train Epoch: 295 \tLoss: 0.8888\tDepression Accuracy: 0.7098\n",
      "Train Epoch: 296 \tLoss: 0.8875\tDepression Accuracy: 0.7105\n",
      "Train Epoch: 297 \tLoss: 0.8862\tDepression Accuracy: 0.7111\n",
      "Train Epoch: 298 \tLoss: 0.8849\tDepression Accuracy: 0.7118\n",
      "Train Epoch: 299 \tLoss: 0.8835\tDepression Accuracy: 0.7125\n",
      "Test Epoch: 0 \tLoss: 1.5276\tDepression Accuracy: 0.3834\n",
      "Test Epoch: 1 \tLoss: 1.4912\tDepression Accuracy: 0.3981\n",
      "Test Epoch: 2 \tLoss: 1.4545\tDepression Accuracy: 0.4128\n",
      "Test Epoch: 3 \tLoss: 1.4217\tDepression Accuracy: 0.4235\n",
      "Test Epoch: 4 \tLoss: 1.3997\tDepression Accuracy: 0.4323\n",
      "Test Epoch: 5 \tLoss: 1.3733\tDepression Accuracy: 0.4411\n",
      "Test Epoch: 6 \tLoss: 1.3484\tDepression Accuracy: 0.4522\n",
      "Test Epoch: 7 \tLoss: 1.3252\tDepression Accuracy: 0.4636\n",
      "Test Epoch: 8 \tLoss: 1.3038\tDepression Accuracy: 0.4729\n",
      "Test Epoch: 9 \tLoss: 1.2849\tDepression Accuracy: 0.4808\n",
      "Test Epoch: 10 \tLoss: 1.2680\tDepression Accuracy: 0.4891\n",
      "Test Epoch: 11 \tLoss: 1.2525\tDepression Accuracy: 0.4968\n",
      "Test Epoch: 12 \tLoss: 1.2378\tDepression Accuracy: 0.5033\n",
      "Test Epoch: 13 \tLoss: 1.2238\tDepression Accuracy: 0.5108\n",
      "Test Epoch: 14 \tLoss: 1.2107\tDepression Accuracy: 0.5175\n",
      "Test Epoch: 15 \tLoss: 1.1981\tDepression Accuracy: 0.5241\n",
      "Test Epoch: 16 \tLoss: 1.1854\tDepression Accuracy: 0.5299\n",
      "Test Epoch: 17 \tLoss: 1.1736\tDepression Accuracy: 0.5363\n",
      "Test Epoch: 18 \tLoss: 1.1627\tDepression Accuracy: 0.5419\n",
      "Test Epoch: 19 \tLoss: 1.1527\tDepression Accuracy: 0.5474\n",
      "Test Epoch: 20 \tLoss: 1.1422\tDepression Accuracy: 0.5532\n",
      "Test Epoch: 21 \tLoss: 1.1317\tDepression Accuracy: 0.5590\n",
      "Test Epoch: 22 \tLoss: 1.1227\tDepression Accuracy: 0.5638\n",
      "Test Epoch: 23 \tLoss: 1.1139\tDepression Accuracy: 0.5686\n",
      "Test Epoch: 24 \tLoss: 1.1049\tDepression Accuracy: 0.5740\n",
      "Test Epoch: 25 \tLoss: 1.0966\tDepression Accuracy: 0.5791\n",
      "Test Epoch: 26 \tLoss: 1.0885\tDepression Accuracy: 0.5841\n",
      "Test Epoch: 27 \tLoss: 1.0803\tDepression Accuracy: 0.5894\n",
      "Test Epoch: 28 \tLoss: 1.0721\tDepression Accuracy: 0.5946\n",
      "Test Epoch: 29 \tLoss: 1.0646\tDepression Accuracy: 0.5990\n",
      "Test Epoch: 30 \tLoss: 1.0571\tDepression Accuracy: 0.6038\n",
      "Test Epoch: 31 \tLoss: 1.0502\tDepression Accuracy: 0.6078\n",
      "Test Epoch: 32 \tLoss: 1.0433\tDepression Accuracy: 0.6123\n",
      "Test Epoch: 33 \tLoss: 1.0365\tDepression Accuracy: 0.6162\n",
      "Test Epoch: 34 \tLoss: 1.0301\tDepression Accuracy: 0.6202\n",
      "Test Epoch: 35 \tLoss: 1.0239\tDepression Accuracy: 0.6241\n",
      "Test Epoch: 36 \tLoss: 1.0180\tDepression Accuracy: 0.6278\n",
      "Test Epoch: 37 \tLoss: 1.0120\tDepression Accuracy: 0.6314\n",
      "Test Epoch: 38 \tLoss: 1.0063\tDepression Accuracy: 0.6349\n",
      "Test Epoch: 39 \tLoss: 1.0007\tDepression Accuracy: 0.6384\n",
      "Test Epoch: 40 \tLoss: 0.9951\tDepression Accuracy: 0.6418\n",
      "Test Epoch: 41 \tLoss: 0.9897\tDepression Accuracy: 0.6451\n",
      "Test Epoch: 42 \tLoss: 0.9846\tDepression Accuracy: 0.6482\n",
      "Test Epoch: 43 \tLoss: 0.9795\tDepression Accuracy: 0.6514\n",
      "Test Epoch: 44 \tLoss: 0.9745\tDepression Accuracy: 0.6547\n",
      "Test Epoch: 45 \tLoss: 0.9694\tDepression Accuracy: 0.6576\n",
      "Test Epoch: 46 \tLoss: 0.9645\tDepression Accuracy: 0.6606\n",
      "Test Epoch: 47 \tLoss: 0.9595\tDepression Accuracy: 0.6638\n",
      "Test Epoch: 48 \tLoss: 0.9549\tDepression Accuracy: 0.6667\n",
      "Test Epoch: 49 \tLoss: 0.9498\tDepression Accuracy: 0.6700\n",
      "Test Epoch: 50 \tLoss: 0.9450\tDepression Accuracy: 0.6729\n",
      "Test Epoch: 51 \tLoss: 0.9403\tDepression Accuracy: 0.6757\n",
      "Test Epoch: 52 \tLoss: 0.9359\tDepression Accuracy: 0.6786\n",
      "Test Epoch: 53 \tLoss: 0.9314\tDepression Accuracy: 0.6814\n",
      "Test Epoch: 54 \tLoss: 0.9268\tDepression Accuracy: 0.6842\n",
      "Test Epoch: 55 \tLoss: 0.9227\tDepression Accuracy: 0.6867\n",
      "Test Epoch: 56 \tLoss: 0.9184\tDepression Accuracy: 0.6894\n",
      "Test Epoch: 57 \tLoss: 0.9144\tDepression Accuracy: 0.6919\n",
      "Test Epoch: 58 \tLoss: 0.9103\tDepression Accuracy: 0.6944\n",
      "Test Epoch: 59 \tLoss: 0.9064\tDepression Accuracy: 0.6968\n",
      "Test Epoch: 60 \tLoss: 0.9025\tDepression Accuracy: 0.6992\n",
      "Test Epoch: 61 \tLoss: 0.8986\tDepression Accuracy: 0.7015\n",
      "Test Epoch: 62 \tLoss: 0.8949\tDepression Accuracy: 0.7038\n",
      "Test Epoch: 63 \tLoss: 0.8910\tDepression Accuracy: 0.7062\n",
      "Test Epoch: 64 \tLoss: 0.8870\tDepression Accuracy: 0.7086\n",
      "Test Epoch: 65 \tLoss: 0.8833\tDepression Accuracy: 0.7108\n",
      "Test Epoch: 66 \tLoss: 0.8796\tDepression Accuracy: 0.7132\n",
      "Test Epoch: 67 \tLoss: 0.8759\tDepression Accuracy: 0.7155\n",
      "Test Epoch: 68 \tLoss: 0.8723\tDepression Accuracy: 0.7176\n",
      "Test Epoch: 69 \tLoss: 0.8689\tDepression Accuracy: 0.7196\n",
      "Test Epoch: 70 \tLoss: 0.8654\tDepression Accuracy: 0.7217\n",
      "Test Epoch: 71 \tLoss: 0.8620\tDepression Accuracy: 0.7237\n",
      "Test Epoch: 72 \tLoss: 0.8586\tDepression Accuracy: 0.7257\n",
      "Test Epoch: 73 \tLoss: 0.8554\tDepression Accuracy: 0.7276\n",
      "Test Epoch: 74 \tLoss: 0.8521\tDepression Accuracy: 0.7295\n",
      "Test Epoch: 75 \tLoss: 0.8488\tDepression Accuracy: 0.7315\n",
      "Test Epoch: 76 \tLoss: 0.8454\tDepression Accuracy: 0.7335\n",
      "Test Epoch: 77 \tLoss: 0.8422\tDepression Accuracy: 0.7353\n",
      "Test Epoch: 78 \tLoss: 0.8389\tDepression Accuracy: 0.7372\n",
      "Test Epoch: 79 \tLoss: 0.8358\tDepression Accuracy: 0.7391\n",
      "Test Epoch: 80 \tLoss: 0.8326\tDepression Accuracy: 0.7410\n",
      "Test Epoch: 81 \tLoss: 0.8295\tDepression Accuracy: 0.7428\n",
      "Test Epoch: 82 \tLoss: 0.8264\tDepression Accuracy: 0.7446\n",
      "Test Epoch: 83 \tLoss: 0.8234\tDepression Accuracy: 0.7463\n",
      "Test Epoch: 84 \tLoss: 0.8205\tDepression Accuracy: 0.7480\n",
      "Test Epoch: 85 \tLoss: 0.8177\tDepression Accuracy: 0.7496\n",
      "Test Epoch: 86 \tLoss: 0.8148\tDepression Accuracy: 0.7513\n",
      "Test Epoch: 87 \tLoss: 0.8122\tDepression Accuracy: 0.7528\n",
      "Test Epoch: 88 \tLoss: 0.8093\tDepression Accuracy: 0.7545\n",
      "Test Epoch: 89 \tLoss: 0.8065\tDepression Accuracy: 0.7562\n",
      "Test Epoch: 90 \tLoss: 0.8037\tDepression Accuracy: 0.7577\n",
      "Test Epoch: 91 \tLoss: 0.8011\tDepression Accuracy: 0.7592\n",
      "Test Epoch: 92 \tLoss: 0.7983\tDepression Accuracy: 0.7608\n",
      "Test Epoch: 93 \tLoss: 0.7957\tDepression Accuracy: 0.7622\n",
      "Test Epoch: 94 \tLoss: 0.7930\tDepression Accuracy: 0.7638\n",
      "Test Epoch: 95 \tLoss: 0.7903\tDepression Accuracy: 0.7652\n",
      "Test Epoch: 96 \tLoss: 0.7877\tDepression Accuracy: 0.7667\n",
      "Test Epoch: 97 \tLoss: 0.7851\tDepression Accuracy: 0.7681\n",
      "Test Epoch: 98 \tLoss: 0.7825\tDepression Accuracy: 0.7697\n",
      "Test Epoch: 99 \tLoss: 0.7799\tDepression Accuracy: 0.7711\n",
      "Test Epoch: 100 \tLoss: 0.7773\tDepression Accuracy: 0.7726\n",
      "Test Epoch: 101 \tLoss: 0.7748\tDepression Accuracy: 0.7740\n",
      "Test Epoch: 102 \tLoss: 0.7722\tDepression Accuracy: 0.7754\n",
      "Test Epoch: 103 \tLoss: 0.7697\tDepression Accuracy: 0.7768\n",
      "Test Epoch: 104 \tLoss: 0.7672\tDepression Accuracy: 0.7782\n",
      "Test Epoch: 105 \tLoss: 0.7647\tDepression Accuracy: 0.7795\n",
      "Test Epoch: 106 \tLoss: 0.7623\tDepression Accuracy: 0.7808\n",
      "Test Epoch: 107 \tLoss: 0.7600\tDepression Accuracy: 0.7821\n",
      "Test Epoch: 108 \tLoss: 0.7576\tDepression Accuracy: 0.7833\n",
      "Test Epoch: 109 \tLoss: 0.7552\tDepression Accuracy: 0.7846\n",
      "Test Epoch: 110 \tLoss: 0.7530\tDepression Accuracy: 0.7858\n",
      "Test Epoch: 111 \tLoss: 0.7507\tDepression Accuracy: 0.7870\n",
      "Test Epoch: 112 \tLoss: 0.7484\tDepression Accuracy: 0.7882\n",
      "Test Epoch: 113 \tLoss: 0.7462\tDepression Accuracy: 0.7895\n",
      "Test Epoch: 114 \tLoss: 0.7440\tDepression Accuracy: 0.7906\n",
      "Test Epoch: 115 \tLoss: 0.7419\tDepression Accuracy: 0.7918\n",
      "Test Epoch: 116 \tLoss: 0.7397\tDepression Accuracy: 0.7930\n",
      "Test Epoch: 117 \tLoss: 0.7375\tDepression Accuracy: 0.7941\n",
      "Test Epoch: 118 \tLoss: 0.7355\tDepression Accuracy: 0.7953\n",
      "Test Epoch: 119 \tLoss: 0.7332\tDepression Accuracy: 0.7965\n",
      "Test Epoch: 120 \tLoss: 0.7311\tDepression Accuracy: 0.7975\n",
      "Test Epoch: 121 \tLoss: 0.7289\tDepression Accuracy: 0.7986\n",
      "Test Epoch: 122 \tLoss: 0.7268\tDepression Accuracy: 0.7996\n",
      "Test Epoch: 123 \tLoss: 0.7248\tDepression Accuracy: 0.8007\n",
      "Test Epoch: 124 \tLoss: 0.7227\tDepression Accuracy: 0.8018\n",
      "Test Epoch: 125 \tLoss: 0.7206\tDepression Accuracy: 0.8029\n",
      "Test Epoch: 126 \tLoss: 0.7185\tDepression Accuracy: 0.8039\n",
      "Test Epoch: 127 \tLoss: 0.7164\tDepression Accuracy: 0.8050\n",
      "Test Epoch: 128 \tLoss: 0.7145\tDepression Accuracy: 0.8060\n",
      "Test Epoch: 129 \tLoss: 0.7126\tDepression Accuracy: 0.8070\n",
      "Test Epoch: 130 \tLoss: 0.7106\tDepression Accuracy: 0.8080\n",
      "Test Epoch: 131 \tLoss: 0.7086\tDepression Accuracy: 0.8091\n",
      "Test Epoch: 132 \tLoss: 0.7066\tDepression Accuracy: 0.8101\n",
      "Test Epoch: 133 \tLoss: 0.7047\tDepression Accuracy: 0.8111\n",
      "Test Epoch: 134 \tLoss: 0.7028\tDepression Accuracy: 0.8120\n",
      "Test Epoch: 135 \tLoss: 0.7008\tDepression Accuracy: 0.8130\n",
      "Test Epoch: 136 \tLoss: 0.6989\tDepression Accuracy: 0.8140\n",
      "Test Epoch: 137 \tLoss: 0.6969\tDepression Accuracy: 0.8150\n",
      "Test Epoch: 138 \tLoss: 0.6950\tDepression Accuracy: 0.8159\n",
      "Test Epoch: 139 \tLoss: 0.6932\tDepression Accuracy: 0.8168\n",
      "Test Epoch: 140 \tLoss: 0.6913\tDepression Accuracy: 0.8177\n",
      "Test Epoch: 141 \tLoss: 0.6895\tDepression Accuracy: 0.8185\n",
      "Test Epoch: 142 \tLoss: 0.6877\tDepression Accuracy: 0.8194\n",
      "Test Epoch: 143 \tLoss: 0.6858\tDepression Accuracy: 0.8204\n",
      "Test Epoch: 144 \tLoss: 0.6841\tDepression Accuracy: 0.8212\n",
      "Test Epoch: 145 \tLoss: 0.6823\tDepression Accuracy: 0.8221\n",
      "Test Epoch: 146 \tLoss: 0.6805\tDepression Accuracy: 0.8230\n",
      "Test Epoch: 147 \tLoss: 0.6787\tDepression Accuracy: 0.8238\n",
      "Test Epoch: 148 \tLoss: 0.6770\tDepression Accuracy: 0.8247\n",
      "Test Epoch: 149 \tLoss: 0.6752\tDepression Accuracy: 0.8256\n",
      "Test Epoch: 150 \tLoss: 0.6735\tDepression Accuracy: 0.8264\n",
      "Test Epoch: 151 \tLoss: 0.6717\tDepression Accuracy: 0.8272\n",
      "Test Epoch: 152 \tLoss: 0.6699\tDepression Accuracy: 0.8280\n",
      "Test Epoch: 153 \tLoss: 0.6682\tDepression Accuracy: 0.8289\n",
      "Test Epoch: 154 \tLoss: 0.6665\tDepression Accuracy: 0.8297\n",
      "Test Epoch: 155 \tLoss: 0.6648\tDepression Accuracy: 0.8305\n",
      "Test Epoch: 156 \tLoss: 0.6631\tDepression Accuracy: 0.8313\n",
      "Test Epoch: 157 \tLoss: 0.6614\tDepression Accuracy: 0.8321\n",
      "Test Epoch: 158 \tLoss: 0.6597\tDepression Accuracy: 0.8329\n",
      "Test Epoch: 159 \tLoss: 0.6581\tDepression Accuracy: 0.8336\n",
      "Test Epoch: 160 \tLoss: 0.6564\tDepression Accuracy: 0.8344\n",
      "Test Epoch: 161 \tLoss: 0.6548\tDepression Accuracy: 0.8352\n",
      "Test Epoch: 162 \tLoss: 0.6531\tDepression Accuracy: 0.8359\n",
      "Test Epoch: 163 \tLoss: 0.6515\tDepression Accuracy: 0.8367\n",
      "Test Epoch: 164 \tLoss: 0.6499\tDepression Accuracy: 0.8374\n",
      "Test Epoch: 165 \tLoss: 0.6483\tDepression Accuracy: 0.8382\n",
      "Test Epoch: 166 \tLoss: 0.6467\tDepression Accuracy: 0.8389\n",
      "Test Epoch: 167 \tLoss: 0.6451\tDepression Accuracy: 0.8396\n",
      "Test Epoch: 168 \tLoss: 0.6436\tDepression Accuracy: 0.8403\n",
      "Test Epoch: 169 \tLoss: 0.6421\tDepression Accuracy: 0.8411\n",
      "Test Epoch: 170 \tLoss: 0.6405\tDepression Accuracy: 0.8418\n",
      "Test Epoch: 171 \tLoss: 0.6390\tDepression Accuracy: 0.8425\n",
      "Test Epoch: 172 \tLoss: 0.6375\tDepression Accuracy: 0.8432\n",
      "Test Epoch: 173 \tLoss: 0.6360\tDepression Accuracy: 0.8439\n",
      "Test Epoch: 174 \tLoss: 0.6344\tDepression Accuracy: 0.8445\n",
      "Test Epoch: 175 \tLoss: 0.6329\tDepression Accuracy: 0.8453\n",
      "Test Epoch: 176 \tLoss: 0.6314\tDepression Accuracy: 0.8459\n",
      "Test Epoch: 177 \tLoss: 0.6300\tDepression Accuracy: 0.8466\n",
      "Test Epoch: 178 \tLoss: 0.6285\tDepression Accuracy: 0.8472\n",
      "Test Epoch: 179 \tLoss: 0.6270\tDepression Accuracy: 0.8479\n",
      "Test Epoch: 180 \tLoss: 0.6255\tDepression Accuracy: 0.8486\n",
      "Test Epoch: 181 \tLoss: 0.6240\tDepression Accuracy: 0.8493\n",
      "Test Epoch: 182 \tLoss: 0.6226\tDepression Accuracy: 0.8499\n",
      "Test Epoch: 183 \tLoss: 0.6212\tDepression Accuracy: 0.8506\n",
      "Test Epoch: 184 \tLoss: 0.6197\tDepression Accuracy: 0.8512\n",
      "Test Epoch: 185 \tLoss: 0.6183\tDepression Accuracy: 0.8518\n",
      "Test Epoch: 186 \tLoss: 0.6169\tDepression Accuracy: 0.8525\n",
      "Test Epoch: 187 \tLoss: 0.6155\tDepression Accuracy: 0.8531\n",
      "Test Epoch: 188 \tLoss: 0.6140\tDepression Accuracy: 0.8537\n",
      "Test Epoch: 189 \tLoss: 0.6126\tDepression Accuracy: 0.8543\n",
      "Test Epoch: 190 \tLoss: 0.6113\tDepression Accuracy: 0.8549\n",
      "Test Epoch: 191 \tLoss: 0.6099\tDepression Accuracy: 0.8555\n",
      "Test Epoch: 192 \tLoss: 0.6085\tDepression Accuracy: 0.8561\n",
      "Test Epoch: 193 \tLoss: 0.6071\tDepression Accuracy: 0.8567\n",
      "Test Epoch: 194 \tLoss: 0.6057\tDepression Accuracy: 0.8573\n",
      "Test Epoch: 195 \tLoss: 0.6043\tDepression Accuracy: 0.8579\n",
      "Test Epoch: 196 \tLoss: 0.6030\tDepression Accuracy: 0.8585\n",
      "Test Epoch: 197 \tLoss: 0.6016\tDepression Accuracy: 0.8591\n",
      "Test Epoch: 198 \tLoss: 0.6003\tDepression Accuracy: 0.8597\n",
      "Test Epoch: 199 \tLoss: 0.5989\tDepression Accuracy: 0.8602\n",
      "Test Epoch: 200 \tLoss: 0.5976\tDepression Accuracy: 0.8608\n",
      "Test Epoch: 201 \tLoss: 0.5963\tDepression Accuracy: 0.8613\n",
      "Test Epoch: 202 \tLoss: 0.5950\tDepression Accuracy: 0.8619\n",
      "Test Epoch: 203 \tLoss: 0.5937\tDepression Accuracy: 0.8625\n",
      "Test Epoch: 204 \tLoss: 0.5924\tDepression Accuracy: 0.8630\n",
      "Test Epoch: 205 \tLoss: 0.5911\tDepression Accuracy: 0.8635\n",
      "Test Epoch: 206 \tLoss: 0.5898\tDepression Accuracy: 0.8641\n",
      "Test Epoch: 207 \tLoss: 0.5886\tDepression Accuracy: 0.8646\n",
      "Test Epoch: 208 \tLoss: 0.5873\tDepression Accuracy: 0.8652\n",
      "Test Epoch: 209 \tLoss: 0.5860\tDepression Accuracy: 0.8657\n",
      "Test Epoch: 210 \tLoss: 0.5848\tDepression Accuracy: 0.8662\n",
      "Test Epoch: 211 \tLoss: 0.5835\tDepression Accuracy: 0.8667\n",
      "Test Epoch: 212 \tLoss: 0.5823\tDepression Accuracy: 0.8673\n",
      "Test Epoch: 213 \tLoss: 0.5811\tDepression Accuracy: 0.8678\n",
      "Test Epoch: 214 \tLoss: 0.5798\tDepression Accuracy: 0.8683\n",
      "Test Epoch: 215 \tLoss: 0.5786\tDepression Accuracy: 0.8688\n",
      "Test Epoch: 216 \tLoss: 0.5774\tDepression Accuracy: 0.8693\n",
      "Test Epoch: 217 \tLoss: 0.5761\tDepression Accuracy: 0.8698\n",
      "Test Epoch: 218 \tLoss: 0.5749\tDepression Accuracy: 0.8703\n",
      "Test Epoch: 219 \tLoss: 0.5737\tDepression Accuracy: 0.8707\n",
      "Test Epoch: 220 \tLoss: 0.5725\tDepression Accuracy: 0.8712\n",
      "Test Epoch: 221 \tLoss: 0.5713\tDepression Accuracy: 0.8717\n",
      "Test Epoch: 222 \tLoss: 0.5701\tDepression Accuracy: 0.8722\n",
      "Test Epoch: 223 \tLoss: 0.5689\tDepression Accuracy: 0.8727\n",
      "Test Epoch: 224 \tLoss: 0.5677\tDepression Accuracy: 0.8731\n",
      "Test Epoch: 225 \tLoss: 0.5665\tDepression Accuracy: 0.8736\n",
      "Test Epoch: 226 \tLoss: 0.5653\tDepression Accuracy: 0.8741\n",
      "Test Epoch: 227 \tLoss: 0.5642\tDepression Accuracy: 0.8745\n",
      "Test Epoch: 228 \tLoss: 0.5630\tDepression Accuracy: 0.8750\n",
      "Test Epoch: 229 \tLoss: 0.5618\tDepression Accuracy: 0.8754\n",
      "Test Epoch: 230 \tLoss: 0.5607\tDepression Accuracy: 0.8759\n",
      "Test Epoch: 231 \tLoss: 0.5595\tDepression Accuracy: 0.8763\n",
      "Test Epoch: 232 \tLoss: 0.5584\tDepression Accuracy: 0.8768\n",
      "Test Epoch: 233 \tLoss: 0.5572\tDepression Accuracy: 0.8772\n",
      "Test Epoch: 234 \tLoss: 0.5561\tDepression Accuracy: 0.8777\n",
      "Test Epoch: 235 \tLoss: 0.5549\tDepression Accuracy: 0.8781\n",
      "Test Epoch: 236 \tLoss: 0.5538\tDepression Accuracy: 0.8785\n",
      "Test Epoch: 237 \tLoss: 0.5526\tDepression Accuracy: 0.8790\n",
      "Test Epoch: 238 \tLoss: 0.5515\tDepression Accuracy: 0.8794\n",
      "Test Epoch: 239 \tLoss: 0.5504\tDepression Accuracy: 0.8799\n",
      "Test Epoch: 240 \tLoss: 0.5493\tDepression Accuracy: 0.8803\n",
      "Test Epoch: 241 \tLoss: 0.5482\tDepression Accuracy: 0.8807\n",
      "Test Epoch: 242 \tLoss: 0.5471\tDepression Accuracy: 0.8811\n",
      "Test Epoch: 243 \tLoss: 0.5460\tDepression Accuracy: 0.8815\n",
      "Test Epoch: 244 \tLoss: 0.5449\tDepression Accuracy: 0.8819\n",
      "Test Epoch: 245 \tLoss: 0.5438\tDepression Accuracy: 0.8823\n",
      "Test Epoch: 246 \tLoss: 0.5428\tDepression Accuracy: 0.8828\n",
      "Test Epoch: 247 \tLoss: 0.5417\tDepression Accuracy: 0.8832\n",
      "Test Epoch: 248 \tLoss: 0.5406\tDepression Accuracy: 0.8835\n",
      "Test Epoch: 249 \tLoss: 0.5396\tDepression Accuracy: 0.8839\n",
      "Test Epoch: 250 \tLoss: 0.5385\tDepression Accuracy: 0.8843\n",
      "Test Epoch: 251 \tLoss: 0.5375\tDepression Accuracy: 0.8847\n",
      "Test Epoch: 252 \tLoss: 0.5364\tDepression Accuracy: 0.8851\n",
      "Test Epoch: 253 \tLoss: 0.5354\tDepression Accuracy: 0.8855\n",
      "Test Epoch: 254 \tLoss: 0.5343\tDepression Accuracy: 0.8859\n",
      "Test Epoch: 255 \tLoss: 0.5333\tDepression Accuracy: 0.8862\n",
      "Test Epoch: 256 \tLoss: 0.5323\tDepression Accuracy: 0.8866\n",
      "Test Epoch: 257 \tLoss: 0.5313\tDepression Accuracy: 0.8869\n",
      "Test Epoch: 258 \tLoss: 0.5303\tDepression Accuracy: 0.8873\n",
      "Test Epoch: 259 \tLoss: 0.5292\tDepression Accuracy: 0.8877\n",
      "Test Epoch: 260 \tLoss: 0.5282\tDepression Accuracy: 0.8880\n",
      "Test Epoch: 261 \tLoss: 0.5272\tDepression Accuracy: 0.8884\n",
      "Test Epoch: 262 \tLoss: 0.5262\tDepression Accuracy: 0.8888\n",
      "Test Epoch: 263 \tLoss: 0.5252\tDepression Accuracy: 0.8891\n",
      "Test Epoch: 264 \tLoss: 0.5242\tDepression Accuracy: 0.8895\n",
      "Test Epoch: 265 \tLoss: 0.5232\tDepression Accuracy: 0.8899\n",
      "Test Epoch: 266 \tLoss: 0.5222\tDepression Accuracy: 0.8902\n",
      "Test Epoch: 267 \tLoss: 0.5212\tDepression Accuracy: 0.8906\n",
      "Test Epoch: 268 \tLoss: 0.5202\tDepression Accuracy: 0.8909\n",
      "Test Epoch: 269 \tLoss: 0.5192\tDepression Accuracy: 0.8913\n",
      "Test Epoch: 270 \tLoss: 0.5183\tDepression Accuracy: 0.8916\n",
      "Test Epoch: 271 \tLoss: 0.5173\tDepression Accuracy: 0.8920\n",
      "Test Epoch: 272 \tLoss: 0.5163\tDepression Accuracy: 0.8923\n",
      "Test Epoch: 273 \tLoss: 0.5154\tDepression Accuracy: 0.8926\n",
      "Test Epoch: 274 \tLoss: 0.5144\tDepression Accuracy: 0.8930\n",
      "Test Epoch: 275 \tLoss: 0.5134\tDepression Accuracy: 0.8933\n",
      "Test Epoch: 276 \tLoss: 0.5124\tDepression Accuracy: 0.8937\n",
      "Test Epoch: 277 \tLoss: 0.5115\tDepression Accuracy: 0.8940\n",
      "Test Epoch: 278 \tLoss: 0.5105\tDepression Accuracy: 0.8943\n",
      "Test Epoch: 279 \tLoss: 0.5095\tDepression Accuracy: 0.8947\n",
      "Test Epoch: 280 \tLoss: 0.5086\tDepression Accuracy: 0.8950\n",
      "Test Epoch: 281 \tLoss: 0.5077\tDepression Accuracy: 0.8953\n",
      "Test Epoch: 282 \tLoss: 0.5067\tDepression Accuracy: 0.8956\n",
      "Test Epoch: 283 \tLoss: 0.5058\tDepression Accuracy: 0.8960\n",
      "Test Epoch: 284 \tLoss: 0.5048\tDepression Accuracy: 0.8963\n",
      "Test Epoch: 285 \tLoss: 0.5039\tDepression Accuracy: 0.8966\n",
      "Test Epoch: 286 \tLoss: 0.5029\tDepression Accuracy: 0.8969\n",
      "Test Epoch: 287 \tLoss: 0.5020\tDepression Accuracy: 0.8972\n",
      "Test Epoch: 288 \tLoss: 0.5011\tDepression Accuracy: 0.8975\n",
      "Test Epoch: 289 \tLoss: 0.5002\tDepression Accuracy: 0.8979\n",
      "Test Epoch: 290 \tLoss: 0.4992\tDepression Accuracy: 0.8982\n",
      "Test Epoch: 291 \tLoss: 0.4983\tDepression Accuracy: 0.8985\n",
      "Test Epoch: 292 \tLoss: 0.4974\tDepression Accuracy: 0.8988\n",
      "Test Epoch: 293 \tLoss: 0.4965\tDepression Accuracy: 0.8991\n",
      "Test Epoch: 294 \tLoss: 0.4956\tDepression Accuracy: 0.8994\n",
      "Test Epoch: 295 \tLoss: 0.4947\tDepression Accuracy: 0.8997\n",
      "Test Epoch: 296 \tLoss: 0.4938\tDepression Accuracy: 0.9000\n",
      "Test Epoch: 297 \tLoss: 0.4929\tDepression Accuracy: 0.9003\n",
      "Test Epoch: 298 \tLoss: 0.4920\tDepression Accuracy: 0.9005\n",
      "Test Epoch: 299 \tLoss: 0.4911\tDepression Accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset_esp_tot)))):\n",
    "    print('Fold {}'.format(fold+1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loaderUns = DataLoader(dataset_esp_tot, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loaderUns = DataLoader(dataset_esp_tot, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    model_TF = Scripted2Unscripted(model_pretrained)\n",
    "\n",
    "    optimizer, scheduler = optimizerNet(model_TF, hparams)\n",
    "\n",
    "    trainXD(epochs, model_TF, train_loaderUns, optimizer, criterion_dep, iter_meter)\n",
    "    testXD(epochs, model_TF, test_loaderUns, optimizer, criterion_anx, iter_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0992\tDepression Accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "acc_dep_list = []\n",
    "loss_list = []\n",
    "label_dep_list = []\n",
    "predicted_list_dep = []\n",
    "loss_tot_list = []\n",
    "accuracy_dep = []\n",
    "\n",
    "for x,y,z in test_loaderUns:\n",
    "    inputs = x\n",
    "    label_dep = y.long()\n",
    "    label_dep_list.extend(label_dep.detach().numpy())\n",
    "\n",
    "    #optimizer.zero_grad()\n",
    "    phq8 = model_TF(inputs.float())\n",
    "    phq8 = phq8.squeeze(0)\n",
    "\n",
    "    predicted_list_dep.extend((torch.max(torch.exp(F.log_softmax(phq8,dim=1)),1)[1]).detach().numpy())\n",
    "\n",
    "    loss = criterion_dep(phq8,label_dep)\n",
    "\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    iter_meter.step()\n",
    "    #total_training_loss += loss\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "    #Track accuracy\n",
    "    total_dep = label_dep.size(0)\n",
    "    _, predicted = torch.max(phq8.data,1)\n",
    "    correct_dep = (predicted == label_dep).sum().item()\n",
    "    acc_dep_list.append(correct_dep/total_dep)  \n",
    "\n",
    "print('Loss: {:.4f}\\tDepression Accuracy: {:.4f}'.format(\n",
    "    np.mean(loss_list),\n",
    "    np.mean(acc_dep_list)\n",
    "))      \n",
    "loss_tot_list.append(np.mean(loss_list))\n",
    "accuracy_dep.append(np.mean(acc_dep_list))\n",
    "\n",
    "#Printing Confusion Matrix\n",
    "classes_dep = ('0','1','2','3','4')\n",
    "cf_matrix_dep = confusion_matrix(label_dep_list, predicted_list_dep)\n",
    "df_cm = pd.DataFrame(cf_matrix_dep/np.sum(cf_matrix_dep)*10,index = [i for i in classes_dep], columns=[i for i in classes_dep])\n",
    "plt.figure(figsize=(12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('Confusion Matrix Depression Testing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Epoch: 0 \tLoss: 2.9652\tDepression Accuracy: 0.2291\tAnxiety Accuracy: 0.3232\n",
      "Train Epoch: 1 \tLoss: 2.9418\tDepression Accuracy: 0.2453\tAnxiety Accuracy: 0.3377\n",
      "Train Epoch: 2 \tLoss: 2.9263\tDepression Accuracy: 0.2583\tAnxiety Accuracy: 0.3436\n",
      "Train Epoch: 3 \tLoss: 2.9137\tDepression Accuracy: 0.2665\tAnxiety Accuracy: 0.3460\n",
      "Train Epoch: 4 \tLoss: 2.9030\tDepression Accuracy: 0.2721\tAnxiety Accuracy: 0.3500\n",
      "Train Epoch: 5 \tLoss: 2.8927\tDepression Accuracy: 0.2783\tAnxiety Accuracy: 0.3529\n",
      "Train Epoch: 6 \tLoss: 2.8845\tDepression Accuracy: 0.2821\tAnxiety Accuracy: 0.3542\n",
      "Train Epoch: 7 \tLoss: 2.8771\tDepression Accuracy: 0.2857\tAnxiety Accuracy: 0.3560\n",
      "Train Epoch: 8 \tLoss: 2.8700\tDepression Accuracy: 0.2899\tAnxiety Accuracy: 0.3571\n",
      "Train Epoch: 9 \tLoss: 2.8636\tDepression Accuracy: 0.2925\tAnxiety Accuracy: 0.3587\n",
      "Train Epoch: 10 \tLoss: 2.8581\tDepression Accuracy: 0.2952\tAnxiety Accuracy: 0.3602\n",
      "Train Epoch: 11 \tLoss: 2.8527\tDepression Accuracy: 0.2977\tAnxiety Accuracy: 0.3616\n",
      "Train Epoch: 12 \tLoss: 2.8473\tDepression Accuracy: 0.3000\tAnxiety Accuracy: 0.3636\n",
      "Train Epoch: 13 \tLoss: 2.8428\tDepression Accuracy: 0.3020\tAnxiety Accuracy: 0.3646\n",
      "Train Epoch: 14 \tLoss: 2.8382\tDepression Accuracy: 0.3040\tAnxiety Accuracy: 0.3661\n",
      "Train Epoch: 15 \tLoss: 2.8338\tDepression Accuracy: 0.3068\tAnxiety Accuracy: 0.3679\n",
      "Train Epoch: 16 \tLoss: 2.8293\tDepression Accuracy: 0.3089\tAnxiety Accuracy: 0.3698\n",
      "Train Epoch: 17 \tLoss: 2.8253\tDepression Accuracy: 0.3104\tAnxiety Accuracy: 0.3715\n",
      "Train Epoch: 18 \tLoss: 2.8212\tDepression Accuracy: 0.3129\tAnxiety Accuracy: 0.3733\n",
      "Train Epoch: 19 \tLoss: 2.8173\tDepression Accuracy: 0.3148\tAnxiety Accuracy: 0.3748\n",
      "Train Epoch: 20 \tLoss: 2.8132\tDepression Accuracy: 0.3167\tAnxiety Accuracy: 0.3766\n",
      "Train Epoch: 21 \tLoss: 2.8092\tDepression Accuracy: 0.3189\tAnxiety Accuracy: 0.3784\n",
      "Train Epoch: 22 \tLoss: 2.8054\tDepression Accuracy: 0.3203\tAnxiety Accuracy: 0.3802\n",
      "Train Epoch: 23 \tLoss: 2.8019\tDepression Accuracy: 0.3220\tAnxiety Accuracy: 0.3816\n",
      "Train Epoch: 24 \tLoss: 2.7981\tDepression Accuracy: 0.3239\tAnxiety Accuracy: 0.3835\n",
      "Train Epoch: 25 \tLoss: 2.7946\tDepression Accuracy: 0.3255\tAnxiety Accuracy: 0.3849\n",
      "Train Epoch: 26 \tLoss: 2.7912\tDepression Accuracy: 0.3270\tAnxiety Accuracy: 0.3860\n",
      "Train Epoch: 27 \tLoss: 2.7878\tDepression Accuracy: 0.3284\tAnxiety Accuracy: 0.3874\n",
      "Train Epoch: 28 \tLoss: 2.7845\tDepression Accuracy: 0.3302\tAnxiety Accuracy: 0.3889\n",
      "Train Epoch: 29 \tLoss: 2.7813\tDepression Accuracy: 0.3316\tAnxiety Accuracy: 0.3900\n",
      "Train Epoch: 30 \tLoss: 2.7780\tDepression Accuracy: 0.3333\tAnxiety Accuracy: 0.3913\n",
      "Train Epoch: 31 \tLoss: 2.7750\tDepression Accuracy: 0.3348\tAnxiety Accuracy: 0.3924\n",
      "Train Epoch: 32 \tLoss: 2.7718\tDepression Accuracy: 0.3362\tAnxiety Accuracy: 0.3938\n",
      "Train Epoch: 33 \tLoss: 2.7687\tDepression Accuracy: 0.3378\tAnxiety Accuracy: 0.3951\n",
      "Train Epoch: 34 \tLoss: 2.7658\tDepression Accuracy: 0.3393\tAnxiety Accuracy: 0.3962\n",
      "Train Epoch: 35 \tLoss: 2.7629\tDepression Accuracy: 0.3406\tAnxiety Accuracy: 0.3976\n",
      "Train Epoch: 36 \tLoss: 2.7599\tDepression Accuracy: 0.3421\tAnxiety Accuracy: 0.3989\n",
      "Train Epoch: 37 \tLoss: 2.7569\tDepression Accuracy: 0.3436\tAnxiety Accuracy: 0.4002\n",
      "Train Epoch: 38 \tLoss: 2.7539\tDepression Accuracy: 0.3451\tAnxiety Accuracy: 0.4014\n",
      "Train Epoch: 39 \tLoss: 2.7510\tDepression Accuracy: 0.3464\tAnxiety Accuracy: 0.4028\n",
      "Train Epoch: 40 \tLoss: 2.7480\tDepression Accuracy: 0.3478\tAnxiety Accuracy: 0.4040\n",
      "Train Epoch: 41 \tLoss: 2.7451\tDepression Accuracy: 0.3493\tAnxiety Accuracy: 0.4052\n",
      "Train Epoch: 42 \tLoss: 2.7423\tDepression Accuracy: 0.3508\tAnxiety Accuracy: 0.4064\n",
      "Train Epoch: 43 \tLoss: 2.7395\tDepression Accuracy: 0.3521\tAnxiety Accuracy: 0.4075\n",
      "Train Epoch: 44 \tLoss: 2.7366\tDepression Accuracy: 0.3536\tAnxiety Accuracy: 0.4087\n",
      "Train Epoch: 45 \tLoss: 2.7338\tDepression Accuracy: 0.3549\tAnxiety Accuracy: 0.4099\n",
      "Train Epoch: 46 \tLoss: 2.7310\tDepression Accuracy: 0.3562\tAnxiety Accuracy: 0.4112\n",
      "Train Epoch: 47 \tLoss: 2.7282\tDepression Accuracy: 0.3575\tAnxiety Accuracy: 0.4123\n",
      "Train Epoch: 48 \tLoss: 2.7255\tDepression Accuracy: 0.3587\tAnxiety Accuracy: 0.4135\n",
      "Train Epoch: 49 \tLoss: 2.7228\tDepression Accuracy: 0.3600\tAnxiety Accuracy: 0.4147\n",
      "Train Epoch: 50 \tLoss: 2.7200\tDepression Accuracy: 0.3614\tAnxiety Accuracy: 0.4158\n",
      "Train Epoch: 51 \tLoss: 2.7173\tDepression Accuracy: 0.3629\tAnxiety Accuracy: 0.4170\n",
      "Train Epoch: 52 \tLoss: 2.7147\tDepression Accuracy: 0.3640\tAnxiety Accuracy: 0.4181\n",
      "Train Epoch: 53 \tLoss: 2.7121\tDepression Accuracy: 0.3654\tAnxiety Accuracy: 0.4192\n",
      "Train Epoch: 54 \tLoss: 2.7094\tDepression Accuracy: 0.3665\tAnxiety Accuracy: 0.4202\n",
      "Train Epoch: 55 \tLoss: 2.7067\tDepression Accuracy: 0.3678\tAnxiety Accuracy: 0.4213\n",
      "Train Epoch: 56 \tLoss: 2.7040\tDepression Accuracy: 0.3692\tAnxiety Accuracy: 0.4224\n",
      "Train Epoch: 57 \tLoss: 2.7013\tDepression Accuracy: 0.3704\tAnxiety Accuracy: 0.4236\n",
      "Train Epoch: 58 \tLoss: 2.6986\tDepression Accuracy: 0.3717\tAnxiety Accuracy: 0.4247\n",
      "Train Epoch: 59 \tLoss: 2.6959\tDepression Accuracy: 0.3729\tAnxiety Accuracy: 0.4259\n",
      "Train Epoch: 60 \tLoss: 2.6931\tDepression Accuracy: 0.3742\tAnxiety Accuracy: 0.4272\n",
      "Train Epoch: 61 \tLoss: 2.6903\tDepression Accuracy: 0.3755\tAnxiety Accuracy: 0.4286\n",
      "Train Epoch: 62 \tLoss: 2.6875\tDepression Accuracy: 0.3768\tAnxiety Accuracy: 0.4298\n",
      "Train Epoch: 63 \tLoss: 2.6848\tDepression Accuracy: 0.3781\tAnxiety Accuracy: 0.4311\n",
      "Train Epoch: 64 \tLoss: 2.6820\tDepression Accuracy: 0.3794\tAnxiety Accuracy: 0.4324\n",
      "Train Epoch: 65 \tLoss: 2.6790\tDepression Accuracy: 0.3807\tAnxiety Accuracy: 0.4337\n",
      "Train Epoch: 66 \tLoss: 2.6759\tDepression Accuracy: 0.3821\tAnxiety Accuracy: 0.4351\n",
      "Train Epoch: 67 \tLoss: 2.6728\tDepression Accuracy: 0.3836\tAnxiety Accuracy: 0.4364\n",
      "Train Epoch: 68 \tLoss: 2.6698\tDepression Accuracy: 0.3852\tAnxiety Accuracy: 0.4375\n",
      "Train Epoch: 69 \tLoss: 2.6666\tDepression Accuracy: 0.3868\tAnxiety Accuracy: 0.4388\n",
      "Train Epoch: 70 \tLoss: 2.6633\tDepression Accuracy: 0.3885\tAnxiety Accuracy: 0.4400\n",
      "Train Epoch: 71 \tLoss: 2.6600\tDepression Accuracy: 0.3901\tAnxiety Accuracy: 0.4412\n",
      "Train Epoch: 72 \tLoss: 2.6569\tDepression Accuracy: 0.3915\tAnxiety Accuracy: 0.4424\n",
      "Train Epoch: 73 \tLoss: 2.6536\tDepression Accuracy: 0.3930\tAnxiety Accuracy: 0.4436\n",
      "Train Epoch: 74 \tLoss: 2.6502\tDepression Accuracy: 0.3946\tAnxiety Accuracy: 0.4449\n",
      "Train Epoch: 75 \tLoss: 2.6469\tDepression Accuracy: 0.3961\tAnxiety Accuracy: 0.4460\n",
      "Train Epoch: 76 \tLoss: 2.6436\tDepression Accuracy: 0.3975\tAnxiety Accuracy: 0.4472\n",
      "Train Epoch: 77 \tLoss: 2.6402\tDepression Accuracy: 0.3990\tAnxiety Accuracy: 0.4485\n",
      "Train Epoch: 78 \tLoss: 2.6368\tDepression Accuracy: 0.4005\tAnxiety Accuracy: 0.4497\n",
      "Train Epoch: 79 \tLoss: 2.6334\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4509\n",
      "Train Epoch: 80 \tLoss: 2.6299\tDepression Accuracy: 0.4034\tAnxiety Accuracy: 0.4521\n",
      "Train Epoch: 81 \tLoss: 2.6264\tDepression Accuracy: 0.4048\tAnxiety Accuracy: 0.4535\n",
      "Train Epoch: 82 \tLoss: 2.6230\tDepression Accuracy: 0.4063\tAnxiety Accuracy: 0.4547\n",
      "Train Epoch: 83 \tLoss: 2.6195\tDepression Accuracy: 0.4077\tAnxiety Accuracy: 0.4560\n",
      "Train Epoch: 84 \tLoss: 2.6161\tDepression Accuracy: 0.4092\tAnxiety Accuracy: 0.4572\n",
      "Train Epoch: 85 \tLoss: 2.6127\tDepression Accuracy: 0.4105\tAnxiety Accuracy: 0.4585\n",
      "Train Epoch: 86 \tLoss: 2.6092\tDepression Accuracy: 0.4120\tAnxiety Accuracy: 0.4597\n",
      "Train Epoch: 87 \tLoss: 2.6058\tDepression Accuracy: 0.4134\tAnxiety Accuracy: 0.4608\n",
      "Train Epoch: 88 \tLoss: 2.6023\tDepression Accuracy: 0.4148\tAnxiety Accuracy: 0.4621\n",
      "Train Epoch: 89 \tLoss: 2.5988\tDepression Accuracy: 0.4162\tAnxiety Accuracy: 0.4633\n",
      "Train Epoch: 90 \tLoss: 2.5954\tDepression Accuracy: 0.4176\tAnxiety Accuracy: 0.4645\n",
      "Train Epoch: 91 \tLoss: 2.5921\tDepression Accuracy: 0.4189\tAnxiety Accuracy: 0.4656\n",
      "Train Epoch: 92 \tLoss: 2.5887\tDepression Accuracy: 0.4203\tAnxiety Accuracy: 0.4667\n",
      "Train Epoch: 93 \tLoss: 2.5853\tDepression Accuracy: 0.4216\tAnxiety Accuracy: 0.4680\n",
      "Train Epoch: 94 \tLoss: 2.5820\tDepression Accuracy: 0.4228\tAnxiety Accuracy: 0.4692\n",
      "Train Epoch: 95 \tLoss: 2.5787\tDepression Accuracy: 0.4241\tAnxiety Accuracy: 0.4703\n",
      "Train Epoch: 96 \tLoss: 2.5754\tDepression Accuracy: 0.4254\tAnxiety Accuracy: 0.4715\n",
      "Train Epoch: 97 \tLoss: 2.5721\tDepression Accuracy: 0.4267\tAnxiety Accuracy: 0.4727\n",
      "Train Epoch: 98 \tLoss: 2.5688\tDepression Accuracy: 0.4279\tAnxiety Accuracy: 0.4738\n",
      "Train Epoch: 99 \tLoss: 2.5654\tDepression Accuracy: 0.4292\tAnxiety Accuracy: 0.4750\n",
      "Train Epoch: 100 \tLoss: 2.5620\tDepression Accuracy: 0.4304\tAnxiety Accuracy: 0.4762\n",
      "Train Epoch: 101 \tLoss: 2.5586\tDepression Accuracy: 0.4317\tAnxiety Accuracy: 0.4774\n",
      "Train Epoch: 102 \tLoss: 2.5553\tDepression Accuracy: 0.4330\tAnxiety Accuracy: 0.4785\n",
      "Train Epoch: 103 \tLoss: 2.5520\tDepression Accuracy: 0.4342\tAnxiety Accuracy: 0.4796\n",
      "Train Epoch: 104 \tLoss: 2.5487\tDepression Accuracy: 0.4354\tAnxiety Accuracy: 0.4808\n",
      "Train Epoch: 105 \tLoss: 2.5453\tDepression Accuracy: 0.4366\tAnxiety Accuracy: 0.4820\n",
      "Train Epoch: 106 \tLoss: 2.5420\tDepression Accuracy: 0.4379\tAnxiety Accuracy: 0.4831\n",
      "Train Epoch: 107 \tLoss: 2.5387\tDepression Accuracy: 0.4391\tAnxiety Accuracy: 0.4843\n",
      "Train Epoch: 108 \tLoss: 2.5354\tDepression Accuracy: 0.4403\tAnxiety Accuracy: 0.4856\n",
      "Train Epoch: 109 \tLoss: 2.5320\tDepression Accuracy: 0.4415\tAnxiety Accuracy: 0.4868\n",
      "Train Epoch: 110 \tLoss: 2.5288\tDepression Accuracy: 0.4427\tAnxiety Accuracy: 0.4879\n",
      "Train Epoch: 111 \tLoss: 2.5254\tDepression Accuracy: 0.4439\tAnxiety Accuracy: 0.4891\n",
      "Train Epoch: 112 \tLoss: 2.5221\tDepression Accuracy: 0.4451\tAnxiety Accuracy: 0.4903\n",
      "Train Epoch: 113 \tLoss: 2.5188\tDepression Accuracy: 0.4463\tAnxiety Accuracy: 0.4915\n",
      "Train Epoch: 114 \tLoss: 2.5156\tDepression Accuracy: 0.4475\tAnxiety Accuracy: 0.4925\n",
      "Train Epoch: 115 \tLoss: 2.5123\tDepression Accuracy: 0.4486\tAnxiety Accuracy: 0.4937\n",
      "Train Epoch: 116 \tLoss: 2.5090\tDepression Accuracy: 0.4498\tAnxiety Accuracy: 0.4949\n",
      "Train Epoch: 117 \tLoss: 2.5057\tDepression Accuracy: 0.4510\tAnxiety Accuracy: 0.4961\n",
      "Train Epoch: 118 \tLoss: 2.5024\tDepression Accuracy: 0.4522\tAnxiety Accuracy: 0.4972\n",
      "Train Epoch: 119 \tLoss: 2.4992\tDepression Accuracy: 0.4533\tAnxiety Accuracy: 0.4983\n",
      "Train Epoch: 120 \tLoss: 2.4960\tDepression Accuracy: 0.4544\tAnxiety Accuracy: 0.4994\n",
      "Train Epoch: 121 \tLoss: 2.4928\tDepression Accuracy: 0.4555\tAnxiety Accuracy: 0.5005\n",
      "Train Epoch: 122 \tLoss: 2.4895\tDepression Accuracy: 0.4566\tAnxiety Accuracy: 0.5017\n",
      "Train Epoch: 123 \tLoss: 2.4863\tDepression Accuracy: 0.4578\tAnxiety Accuracy: 0.5028\n",
      "Train Epoch: 124 \tLoss: 2.4829\tDepression Accuracy: 0.4590\tAnxiety Accuracy: 0.5040\n",
      "Train Epoch: 125 \tLoss: 2.4797\tDepression Accuracy: 0.4601\tAnxiety Accuracy: 0.5051\n",
      "Train Epoch: 126 \tLoss: 2.4764\tDepression Accuracy: 0.4613\tAnxiety Accuracy: 0.5062\n",
      "Train Epoch: 127 \tLoss: 2.4731\tDepression Accuracy: 0.4624\tAnxiety Accuracy: 0.5073\n",
      "Train Epoch: 128 \tLoss: 2.4699\tDepression Accuracy: 0.4635\tAnxiety Accuracy: 0.5084\n",
      "Train Epoch: 129 \tLoss: 2.4666\tDepression Accuracy: 0.4647\tAnxiety Accuracy: 0.5094\n",
      "Train Epoch: 130 \tLoss: 2.4634\tDepression Accuracy: 0.4657\tAnxiety Accuracy: 0.5105\n",
      "Train Epoch: 131 \tLoss: 2.4602\tDepression Accuracy: 0.4668\tAnxiety Accuracy: 0.5116\n",
      "Train Epoch: 132 \tLoss: 2.4569\tDepression Accuracy: 0.4680\tAnxiety Accuracy: 0.5127\n",
      "Train Epoch: 133 \tLoss: 2.4537\tDepression Accuracy: 0.4690\tAnxiety Accuracy: 0.5137\n",
      "Train Epoch: 134 \tLoss: 2.4505\tDepression Accuracy: 0.4701\tAnxiety Accuracy: 0.5148\n",
      "Train Epoch: 135 \tLoss: 2.4473\tDepression Accuracy: 0.4712\tAnxiety Accuracy: 0.5159\n",
      "Train Epoch: 136 \tLoss: 2.4441\tDepression Accuracy: 0.4723\tAnxiety Accuracy: 0.5170\n",
      "Train Epoch: 137 \tLoss: 2.4409\tDepression Accuracy: 0.4734\tAnxiety Accuracy: 0.5181\n",
      "Train Epoch: 138 \tLoss: 2.4377\tDepression Accuracy: 0.4745\tAnxiety Accuracy: 0.5191\n",
      "Train Epoch: 139 \tLoss: 2.4345\tDepression Accuracy: 0.4756\tAnxiety Accuracy: 0.5202\n",
      "Train Epoch: 140 \tLoss: 2.4313\tDepression Accuracy: 0.4767\tAnxiety Accuracy: 0.5212\n",
      "Train Epoch: 141 \tLoss: 2.4281\tDepression Accuracy: 0.4778\tAnxiety Accuracy: 0.5223\n",
      "Train Epoch: 142 \tLoss: 2.4249\tDepression Accuracy: 0.4789\tAnxiety Accuracy: 0.5233\n",
      "Train Epoch: 143 \tLoss: 2.4217\tDepression Accuracy: 0.4799\tAnxiety Accuracy: 0.5244\n",
      "Train Epoch: 144 \tLoss: 2.4185\tDepression Accuracy: 0.4811\tAnxiety Accuracy: 0.5255\n",
      "Train Epoch: 145 \tLoss: 2.4154\tDepression Accuracy: 0.4821\tAnxiety Accuracy: 0.5265\n",
      "Train Epoch: 146 \tLoss: 2.4122\tDepression Accuracy: 0.4831\tAnxiety Accuracy: 0.5276\n",
      "Train Epoch: 147 \tLoss: 2.4090\tDepression Accuracy: 0.4842\tAnxiety Accuracy: 0.5286\n",
      "Train Epoch: 148 \tLoss: 2.4059\tDepression Accuracy: 0.4853\tAnxiety Accuracy: 0.5297\n",
      "Train Epoch: 149 \tLoss: 2.4027\tDepression Accuracy: 0.4863\tAnxiety Accuracy: 0.5308\n",
      "Test Epoch: 0 \tLoss: 2.6092\tDepression Accuracy: 0.4028\tAnxiety Accuracy: 0.4422\n",
      "Test Epoch: 1 \tLoss: 2.6105\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4380\n",
      "Test Epoch: 2 \tLoss: 2.6140\tDepression Accuracy: 0.3992\tAnxiety Accuracy: 0.4388\n",
      "Test Epoch: 3 \tLoss: 2.6173\tDepression Accuracy: 0.3992\tAnxiety Accuracy: 0.4394\n",
      "Test Epoch: 4 \tLoss: 2.6170\tDepression Accuracy: 0.3994\tAnxiety Accuracy: 0.4386\n",
      "Test Epoch: 5 \tLoss: 2.6175\tDepression Accuracy: 0.3991\tAnxiety Accuracy: 0.4380\n",
      "Test Epoch: 6 \tLoss: 2.6190\tDepression Accuracy: 0.3993\tAnxiety Accuracy: 0.4381\n",
      "Test Epoch: 7 \tLoss: 2.6183\tDepression Accuracy: 0.3975\tAnxiety Accuracy: 0.4390\n",
      "Test Epoch: 8 \tLoss: 2.6196\tDepression Accuracy: 0.3979\tAnxiety Accuracy: 0.4382\n",
      "Test Epoch: 9 \tLoss: 2.6169\tDepression Accuracy: 0.3992\tAnxiety Accuracy: 0.4400\n",
      "Test Epoch: 10 \tLoss: 2.6185\tDepression Accuracy: 0.3998\tAnxiety Accuracy: 0.4402\n",
      "Test Epoch: 11 \tLoss: 2.6177\tDepression Accuracy: 0.4000\tAnxiety Accuracy: 0.4403\n",
      "Test Epoch: 12 \tLoss: 2.6164\tDepression Accuracy: 0.4014\tAnxiety Accuracy: 0.4402\n",
      "Test Epoch: 13 \tLoss: 2.6163\tDepression Accuracy: 0.4009\tAnxiety Accuracy: 0.4398\n",
      "Test Epoch: 14 \tLoss: 2.6160\tDepression Accuracy: 0.4018\tAnxiety Accuracy: 0.4401\n",
      "Test Epoch: 15 \tLoss: 2.6157\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4405\n",
      "Test Epoch: 16 \tLoss: 2.6159\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4402\n",
      "Test Epoch: 17 \tLoss: 2.6169\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4403\n",
      "Test Epoch: 18 \tLoss: 2.6165\tDepression Accuracy: 0.4018\tAnxiety Accuracy: 0.4407\n",
      "Test Epoch: 19 \tLoss: 2.6168\tDepression Accuracy: 0.4015\tAnxiety Accuracy: 0.4402\n",
      "Test Epoch: 20 \tLoss: 2.6171\tDepression Accuracy: 0.4015\tAnxiety Accuracy: 0.4407\n",
      "Test Epoch: 21 \tLoss: 2.6162\tDepression Accuracy: 0.4018\tAnxiety Accuracy: 0.4408\n",
      "Test Epoch: 22 \tLoss: 2.6168\tDepression Accuracy: 0.4011\tAnxiety Accuracy: 0.4408\n",
      "Test Epoch: 23 \tLoss: 2.6164\tDepression Accuracy: 0.4012\tAnxiety Accuracy: 0.4407\n",
      "Test Epoch: 24 \tLoss: 2.6158\tDepression Accuracy: 0.4015\tAnxiety Accuracy: 0.4408\n",
      "Test Epoch: 25 \tLoss: 2.6160\tDepression Accuracy: 0.4014\tAnxiety Accuracy: 0.4411\n",
      "Test Epoch: 26 \tLoss: 2.6162\tDepression Accuracy: 0.4014\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 27 \tLoss: 2.6159\tDepression Accuracy: 0.4014\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 28 \tLoss: 2.6158\tDepression Accuracy: 0.4016\tAnxiety Accuracy: 0.4410\n",
      "Test Epoch: 29 \tLoss: 2.6155\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4410\n",
      "Test Epoch: 30 \tLoss: 2.6155\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4409\n",
      "Test Epoch: 31 \tLoss: 2.6150\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4411\n",
      "Test Epoch: 32 \tLoss: 2.6153\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4410\n",
      "Test Epoch: 33 \tLoss: 2.6153\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4408\n",
      "Test Epoch: 34 \tLoss: 2.6151\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4408\n",
      "Test Epoch: 35 \tLoss: 2.6149\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 36 \tLoss: 2.6138\tDepression Accuracy: 0.4028\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 37 \tLoss: 2.6137\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 38 \tLoss: 2.6130\tDepression Accuracy: 0.4029\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 39 \tLoss: 2.6129\tDepression Accuracy: 0.4031\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 40 \tLoss: 2.6132\tDepression Accuracy: 0.4030\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 41 \tLoss: 2.6132\tDepression Accuracy: 0.4030\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 42 \tLoss: 2.6131\tDepression Accuracy: 0.4029\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 43 \tLoss: 2.6134\tDepression Accuracy: 0.4028\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 44 \tLoss: 2.6133\tDepression Accuracy: 0.4029\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 45 \tLoss: 2.6135\tDepression Accuracy: 0.4028\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 46 \tLoss: 2.6130\tDepression Accuracy: 0.4029\tAnxiety Accuracy: 0.4421\n",
      "Test Epoch: 47 \tLoss: 2.6129\tDepression Accuracy: 0.4028\tAnxiety Accuracy: 0.4422\n",
      "Test Epoch: 48 \tLoss: 2.6129\tDepression Accuracy: 0.4027\tAnxiety Accuracy: 0.4421\n",
      "Test Epoch: 49 \tLoss: 2.6129\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 50 \tLoss: 2.6133\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 51 \tLoss: 2.6132\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 52 \tLoss: 2.6131\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 53 \tLoss: 2.6134\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 54 \tLoss: 2.6132\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 55 \tLoss: 2.6130\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 56 \tLoss: 2.6129\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 57 \tLoss: 2.6129\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 58 \tLoss: 2.6128\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 59 \tLoss: 2.6126\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 60 \tLoss: 2.6127\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4410\n",
      "Test Epoch: 61 \tLoss: 2.6124\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4411\n",
      "Test Epoch: 62 \tLoss: 2.6125\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 63 \tLoss: 2.6126\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4411\n",
      "Test Epoch: 64 \tLoss: 2.6123\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4411\n",
      "Test Epoch: 65 \tLoss: 2.6124\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4411\n",
      "Test Epoch: 66 \tLoss: 2.6123\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 67 \tLoss: 2.6121\tDepression Accuracy: 0.4025\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 68 \tLoss: 2.6121\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 69 \tLoss: 2.6118\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 70 \tLoss: 2.6119\tDepression Accuracy: 0.4027\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 71 \tLoss: 2.6120\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 72 \tLoss: 2.6121\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 73 \tLoss: 2.6120\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 74 \tLoss: 2.6118\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 75 \tLoss: 2.6119\tDepression Accuracy: 0.4026\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 76 \tLoss: 2.6119\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 77 \tLoss: 2.6117\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 78 \tLoss: 2.6117\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 79 \tLoss: 2.6116\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 80 \tLoss: 2.6115\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 81 \tLoss: 2.6117\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 82 \tLoss: 2.6116\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 83 \tLoss: 2.6118\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 84 \tLoss: 2.6123\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 85 \tLoss: 2.6124\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 86 \tLoss: 2.6126\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 87 \tLoss: 2.6126\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 88 \tLoss: 2.6126\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 89 \tLoss: 2.6127\tDepression Accuracy: 0.4023\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 90 \tLoss: 2.6126\tDepression Accuracy: 0.4024\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 91 \tLoss: 2.6127\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 92 \tLoss: 2.6127\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4412\n",
      "Test Epoch: 93 \tLoss: 2.6127\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 94 \tLoss: 2.6126\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 95 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 96 \tLoss: 2.6128\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4413\n",
      "Test Epoch: 97 \tLoss: 2.6126\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 98 \tLoss: 2.6127\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 99 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 100 \tLoss: 2.6129\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 101 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 102 \tLoss: 2.6126\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 103 \tLoss: 2.6126\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 104 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 105 \tLoss: 2.6129\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 106 \tLoss: 2.6129\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 107 \tLoss: 2.6129\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 108 \tLoss: 2.6128\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 109 \tLoss: 2.6126\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 110 \tLoss: 2.6128\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 111 \tLoss: 2.6129\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 112 \tLoss: 2.6130\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 113 \tLoss: 2.6131\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 114 \tLoss: 2.6130\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 115 \tLoss: 2.6130\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 116 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 117 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4415\n",
      "Test Epoch: 118 \tLoss: 2.6129\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4414\n",
      "Test Epoch: 119 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 120 \tLoss: 2.6128\tDepression Accuracy: 0.4019\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 121 \tLoss: 2.6128\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 122 \tLoss: 2.6129\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4416\n",
      "Test Epoch: 123 \tLoss: 2.6128\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 124 \tLoss: 2.6128\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 125 \tLoss: 2.6128\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4417\n",
      "Test Epoch: 126 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 127 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 128 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 129 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 130 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 131 \tLoss: 2.6125\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 132 \tLoss: 2.6125\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 133 \tLoss: 2.6124\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 134 \tLoss: 2.6125\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 135 \tLoss: 2.6125\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 136 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 137 \tLoss: 2.6128\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 138 \tLoss: 2.6128\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4418\n",
      "Test Epoch: 139 \tLoss: 2.6128\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 140 \tLoss: 2.6129\tDepression Accuracy: 0.4020\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 141 \tLoss: 2.6126\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4420\n",
      "Test Epoch: 142 \tLoss: 2.6127\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4419\n",
      "Test Epoch: 143 \tLoss: 2.6127\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4420\n",
      "Test Epoch: 144 \tLoss: 2.6127\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4420\n",
      "Test Epoch: 145 \tLoss: 2.6127\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4420\n",
      "Test Epoch: 146 \tLoss: 2.6126\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4420\n",
      "Test Epoch: 147 \tLoss: 2.6125\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4420\n",
      "Test Epoch: 148 \tLoss: 2.6123\tDepression Accuracy: 0.4022\tAnxiety Accuracy: 0.4421\n",
      "Test Epoch: 149 \tLoss: 2.6124\tDepression Accuracy: 0.4021\tAnxiety Accuracy: 0.4421\n",
      "Fold 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m loss_anx \u001b[39m=\u001b[39m criterion_anx(gad7, label_anx)\n\u001b[0;32m     56\u001b[0m loss \u001b[39m=\u001b[39m loss_dep \u001b[39m+\u001b[39m loss_anx\n\u001b[1;32m---> 57\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     58\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     59\u001b[0m iter_meter\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\ericq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\ericq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from networks_v2 import HydraNet\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset_esp_tot)))):\n",
    "    print('Fold {}'.format(fold+1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset_esp_tot, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset_esp_tot, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "    model_mlt = HydraNet(\n",
    "        hparams['n_cnn_layers'],\n",
    "        hparams['rnn_dim'],\n",
    "        hparams['h_rnn_layers'],\n",
    "        hparams['n_rnn_layers'],\n",
    "        hparams['n_class'],\n",
    "        hparams['stride'],\n",
    "        hparams['dropout']\n",
    "    ).to(device).float()\n",
    "    optimizer, scheduler = optimizerNet(model_mlt, hparams)\n",
    "\n",
    "    acc_dep_list = []\n",
    "    acc_anx_list = []\n",
    "    loss_list = []\n",
    "    label_dep_list = []\n",
    "    label_anx_list = []\n",
    "    predicted_list_anx = []\n",
    "    predicted_list_dep = []\n",
    "    loss_tot_list = []\n",
    "    accuracy_dep = []\n",
    "    accuracy_anx = []\n",
    "\n",
    "    #Training\n",
    "    for epoch in range(epochs):\n",
    "        model_mlt.train()\n",
    "        total_training_loss = 0\n",
    "\n",
    "        for x,y,z in train_loader:\n",
    "            inputs = x\n",
    "            label_dep = y.long()\n",
    "            label_anx = z.long()\n",
    "            label_dep_list.extend(label_dep.detach().numpy())\n",
    "            label_anx_list.extend(label_anx.detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            phq8, gad7 = model_mlt(inputs.float())\n",
    "            phq8 = phq8.squeeze(0)\n",
    "            gad7 = gad7.squeeze(0)\n",
    "\n",
    "            predicted_list_dep.extend((torch.max(torch.exp(F.log_softmax(phq8,dim=1)),1)[1]).detach().numpy())\n",
    "            predicted_list_anx.extend((torch.max(torch.exp(F.log_softmax(gad7,dim=1)),1)[1]).detach().numpy())\n",
    "\n",
    "            loss_dep = criterion_dep(phq8,label_dep)\n",
    "            loss_anx = criterion_anx(gad7, label_anx)\n",
    "\n",
    "            loss = loss_dep + loss_anx\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_meter.step()\n",
    "            total_training_loss += loss\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            #Track accuracy\n",
    "            total_dep = label_dep.size(0)\n",
    "            _, predicted = torch.max(phq8.data,1)\n",
    "            correct_dep = (predicted == label_dep).sum().item()\n",
    "            acc_dep_list.append(correct_dep/total_dep)  \n",
    "\n",
    "            total_anx = label_anx.size(0)\n",
    "            _, predicted = torch.max(gad7.data,1)\n",
    "            correct_anx = (predicted==label_anx).sum().item()\n",
    "            acc_anx_list.append(correct_anx/total_anx)\n",
    "\n",
    "        print('Train Epoch: {} \\tLoss: {:.4f}\\tDepression Accuracy: {:.4f}\\tAnxiety Accuracy: {:.4f}'.format(\n",
    "            epoch,\n",
    "            np.mean(loss_list),\n",
    "            np.mean(acc_dep_list),\n",
    "            np.mean(acc_anx_list)\n",
    "        ))      \n",
    "        loss_tot_list.append(np.mean(loss_list))\n",
    "        accuracy_dep.append(np.mean(acc_dep_list))\n",
    "        accuracy_anx.append(np.mean(acc_anx_list))\n",
    "        \n",
    "    #Printing Confusion Matrix\n",
    "    classes_dep = ('0','1','2','3','4')\n",
    "    cf_matrix_dep = confusion_matrix(label_dep_list, predicted_list_dep)\n",
    "    df_cm = pd.DataFrame(cf_matrix_dep/np.sum(cf_matrix_dep)*10,index = [i for i in classes_dep], columns=[i for i in classes_dep])\n",
    "    plt.figure(figsize=(12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('Confusion Matrix Depression Training')\n",
    "\n",
    "    classes_anx = ('0','1','2','3')\n",
    "    cf_matrix_anx = confusion_matrix(label_anx_list, predicted_list_anx)\n",
    "    df_cm = pd.DataFrame(cf_matrix_anx/np.sum(cf_matrix_anx)*10,index = [i for i in classes_anx], columns=[i for i in classes_anx])\n",
    "    plt.figure(figsize=(12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('Confusion Matrix Anxiety Training')\n",
    "\n",
    "    fig, axs = plt.subplots(3)\n",
    "    axs[0].plot(range(epochs), loss_tot_list)\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].set(xlabel= 'Epoch', ylabel='Loss')\n",
    "    axs[1].plot(range(epochs), accuracy_dep)\n",
    "    axs[1].set_title('Training Depression Accuracy')\n",
    "    axs[1].set(xlabel= 'Epoch', ylabel='Accuracy')\n",
    "    axs[2].plot(range(epochs), accuracy_anx)\n",
    "    axs[2].set_title('Training Anxiety Accuracy')\n",
    "    axs[2].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    #Test\n",
    "    acc_dep_list = []\n",
    "    acc_anx_list = []\n",
    "    loss_list = []\n",
    "    label_dep_list = []\n",
    "    label_anx_list = []\n",
    "    predicted_list_anx = []\n",
    "    predicted_list_dep = []\n",
    "    loss_tot_list = []\n",
    "    accuracy_dep = []\n",
    "    accuracy_anx = []\n",
    "    for epoch in range(epochs):\n",
    "        model_mlt.train()\n",
    "        total_training_loss = 0\n",
    "\n",
    "        for x,y,z in test_loader:\n",
    "            inputs = x\n",
    "            label_dep = y.long()\n",
    "            label_anx = z.long()\n",
    "            label_dep_list.extend(label_dep.detach().numpy())\n",
    "            label_anx_list.extend(label_anx.detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            phq8, gad7 = model_mlt(inputs.float())\n",
    "            phq8 = phq8.squeeze(0)\n",
    "            gad7 = gad7.squeeze(0)\n",
    "\n",
    "            predicted_list_dep.extend((torch.max(torch.exp(F.log_softmax(phq8,dim=1)),1)[1]).detach().numpy())\n",
    "            predicted_list_anx.extend((torch.max(torch.exp(F.log_softmax(gad7,dim=1)),1)[1]).detach().numpy())\n",
    "\n",
    "            loss_dep = criterion_dep(phq8,label_dep)\n",
    "            loss_anx = criterion_anx(gad7, label_anx)\n",
    "\n",
    "            loss = loss_dep + loss_anx\n",
    "            #loss.backward()\n",
    "            #optimizer.step()\n",
    "            #iter_meter.step()\n",
    "            total_training_loss += loss\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            #Track accuracy\n",
    "            total_dep = label_dep.size(0)\n",
    "            _, predicted = torch.max(phq8.data,1)\n",
    "            correct_dep = (predicted == label_dep).sum().item()\n",
    "            acc_dep_list.append(correct_dep/total_dep)  \n",
    "\n",
    "            total_anx = label_anx.size(0)\n",
    "            _, predicted = torch.max(gad7.data,1)\n",
    "            correct_anx = (predicted==label_anx).sum().item()\n",
    "            acc_anx_list.append(correct_anx/total_anx)\n",
    "\n",
    "        print('Test Epoch: {} \\tLoss: {:.4f}\\tDepression Accuracy: {:.4f}\\tAnxiety Accuracy: {:.4f}'.format(\n",
    "            epoch,\n",
    "            np.mean(loss_list),\n",
    "            np.mean(acc_dep_list),\n",
    "            np.mean(acc_anx_list)\n",
    "        ))      \n",
    "        loss_tot_list.append(np.mean(loss_list))\n",
    "        accuracy_dep.append(np.mean(acc_dep_list))\n",
    "        accuracy_anx.append(np.mean(acc_anx_list))\n",
    "        \n",
    "    #Printing Confusion Matrix\n",
    "    classes_dep = ('0','1','2','3','4')\n",
    "    cf_matrix_dep = confusion_matrix(label_dep_list, predicted_list_dep)\n",
    "    df_cm = pd.DataFrame(cf_matrix_dep/np.sum(cf_matrix_dep)*10,index = [i for i in classes_dep], columns=[i for i in classes_dep])\n",
    "    plt.figure(figsize=(12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('Confusion Matrix Depression Test')\n",
    "\n",
    "    classes_anx = ('0','1','2','3')\n",
    "    cf_matrix_anx = confusion_matrix(label_anx_list, predicted_list_anx)\n",
    "    df_cm = pd.DataFrame(cf_matrix_anx/np.sum(cf_matrix_anx)*10,index = [i for i in classes_anx], columns=[i for i in classes_anx])\n",
    "    plt.figure(figsize=(12,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig('Confusion Matrix Anxiety Test')\n",
    "\n",
    "    fig, axs = plt.subplots(3)\n",
    "    axs[0].plot(range(epochs), loss_tot_list)\n",
    "    axs[0].set_title('Test Loss')\n",
    "    axs[0].set(xlabel= 'Epoch', ylabel='Loss')\n",
    "    axs[1].plot(range(epochs), accuracy_dep)\n",
    "    axs[1].set_title('Test Depression Accuracy')\n",
    "    axs[1].set(xlabel= 'Epoch', ylabel='Accuracy')\n",
    "    axs[2].plot(range(epochs), accuracy_anx)\n",
    "    axs[2].set_title('Test Anxiety Accuracy')\n",
    "    axs[2].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "    plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bdda07c8f3c0d50e657417337633c7d770439b214bea89575d6ab5962ed7357"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
